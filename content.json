{"meta":{"title":"Zhou_Moon","subtitle":"<三人行比有我师>","description":"周海军的博客","author":"ZhouMoon","url":"http://zhoumoon.github.io","root":"/"},"pages":[{"title":"Tags","date":"2020-05-05T07:07:51.000Z","updated":"2020-05-05T07:14:36.573Z","comments":false,"path":"tags/index.html","permalink":"http://zhoumoon.github.io/tags/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-02-08T08:03:32.336Z","updated":"2019-08-01T11:17:12.000Z","comments":false,"path":"repository/index.html","permalink":"http://zhoumoon.github.io/repository/index.html","excerpt":"","text":""},{"title":"关于💥","date":"2021-02-08T08:28:59.446Z","updated":"2021-02-08T08:28:59.446Z","comments":false,"path":"about/index.html","permalink":"http://zhoumoon.github.io/about/index.html","excerpt":"","text":"版本: 1.0.1版权所有: Moon….."},{"title":"分类","date":"2021-02-08T08:05:54.339Z","updated":"2019-08-01T11:17:12.000Z","comments":false,"path":"categories/index.html","permalink":"http://zhoumoon.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Log4j 配置祥解","slug":"Log4j配置详解","date":"2020-03-10T12:12:01.000Z","updated":"2021-02-08T08:11:26.271Z","comments":false,"path":"2020/03/10/Log4j配置详解/","link":"","permalink":"http://zhoumoon.github.io/2020/03/10/Log4j配置详解/","excerpt":"","text":"转载：http://www.360doc.com/content/17/0824/16/46744981_681796916.shtml Log4J的配置文件(Configuration File)就是用来设置记录器的级别、存放器和布局的，它可接key=value格式的设置或xml格式的设置信息。通过配置，可以创建出Log4J的运行环境。 配置文件Log4J配置文件的基本格式如下： 1234567891011121314 #配置根Loggerlog4j.rootLogger = [ level ] , appenderName1 , appenderName2 , …#配置日志信息输出目的地Appenderlog4j.appender.appenderName = fully.qualified.name.of.appender.class log4j.appender.appenderName.option1 = value1 … log4j.appender.appenderName.optionN = valueN #配置日志信息的格式（布局）log4j.appender.appenderName.layout = fully.qualified.name.of.layout.class log4j.appender.appenderName.layout.option1 = value1 … log4j.appender.appenderName.layout.optionN = valueN 其中 [level] 是日志输出级别，共有5级： 12345FATAL 0 ERROR 3 WARN 4 INFO 6 DEBUG 7 Appender 为日志输出目的地，Log4j提供的appender有以下几种： 12345org.apache.log4j.ConsoleAppender（控制台），org.apache.log4j.FileAppender（文件），org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件），org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件），org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） Layout：日志输出格式，Log4j提供的layout有以下几种： 1234org.apache.log4j.HTMLLayout（以HTML表格形式布局），org.apache.log4j.PatternLayout（可以灵活地指定布局模式），org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） 打印参数: Log4J采用类似C语言中的printf函数的打印格式格式化日志信息，如下: 12345678%m 输出代码中指定的消息 %p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL %r 输出自应用启动到输出该log信息耗费的毫秒数 %c 输出所属的类目，通常就是所在类的全名 %t 输出产生该日志事件的线程名 %n 输出一个回车换行符，Windows平台为“\\r\\n”，Unix平台为“\\n” %d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d&#123;yyy MMM dd HH:mm:ss , SSS&#125;，输出类似：2002年10月18日 22 ： 10 ： 28 ， 921 %l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java: 10 ) 2.在代码中初始化Logger:1）在程序中调用BasicConfigurator.configure()方法：给根记录器增加一个ConsoleAppender，输出格式通过PatternLayout设为”%-4r [%t] %-5p %c %x - %m%n”，还有根记录器的默认级别是Level.DEBUG.2）配置放在文件里，通过命令行参数传递文件名字，通过PropertyConfigurator.configure(args[x])解析并配置；3）配置放在文件里，通过环境变量传递文件名等信息，利用log4j默认的初始化过程解析并配置；4）配置放在文件里，通过应用服务器配置传递文件名等信息，利用一个特殊的servlet来完成配置。 3.为不同的 Appender 设置日志输出级别：当调试系统时，我们往往注意的只是异常级别的日志输出，但是通常所有级别的输出都是放在一个文件里的，如果日志输出的级别是BUG！？那就慢慢去找吧。这时我们也许会想要是能把异常信息单独输出到一个文件里该多好啊。当然可以，Log4j已经提供了这样的功能，我们只需要在配置中修改Appender的Threshold 就能实现,比如下面的例子： 12345678910111213141516171819202122232425### set log levels ###log4j.rootLogger = debug , stdout , D , E### 输出到控制台 ###log4j.appender.stdout = org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target = System.outlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = %d&#123;ABSOLUTE&#125; %5p %c&#123; 1 &#125;:%L - %m%n### 输出到日志文件 ###log4j.appender.D = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.D.File = logs/log.loglog4j.appender.D.Append = truelog4j.appender.D.Threshold = DEBUG ## 输出DEBUG级别以上的日志log4j.appender.D.layout = org.apache.log4j.PatternLayoutlog4j.appender.D.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125; [ %t:%r ] - [ %p ] %m%n### 保存异常信息到单独文件 ###log4j.appender.D = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.D.File = logs/error.log ## 异常日志文件名log4j.appender.D.Append = truelog4j.appender.D.Threshold = ERROR ## 只输出ERROR级别以上的日志!!!log4j.appender.D.layout = org.apache.log4j.PatternLayoutlog4j.appender.D.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125; [ %t:%r ] - [ %p ] %m%n``` public class TestLog4j { public static void main(String[] args) { PropertyConfigurator.configure( “ D:/Code/conf/log4j.properties “ ); Logger logger = Logger.getLogger(TestLog4j. class ); logger.debug( “ debug “ ); logger.error( “ error “ ); } 12345678运行一下，看看异常信息是不是保存在了一个单独的文件error.log中。\\=====================================================================资料：1. log4j.properties文件例子，这个文件就是本文的重点，也就是log4j的配置文件: Set root logger level to DEBUG and its only appender to A1#log4j中有五级logger #FATAL 0 #ERROR 3 #WARN 4 #INFO 6 #DEBUG 7 #配置根Logger，其语法为： #log4j.rootLogger = [ level ] , appenderName, appenderName, …log4j.rootLogger=INFO, A1 ,R #这一句设置以为着所有的log都输出 #如果为log4j.rootLogger=WARN, 则意味着只有WARN,ERROR,FATAL #被输出，DEBUG,INFO将被屏蔽掉. A1 is set to be a ConsoleAppender.#log4j中Appender有几层如控制台、文件、GUI组件、甚至是套接口服务器、NT的事件记录器、UNIX Syslog守护进程等 #ConsoleAppender输出到控制台log4j.appender.A1=org.apache.log4j.ConsoleAppender A1 使用的输出布局，其中log4j提供4种布局. org.apache.log4j.HTMLLayout（以HTML表格形式布局）#org.apache.log4j.PatternLayout（可以灵活地指定布局模式）， #org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）， #org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） log4j.appender.A1.layout=org.apache.log4j.PatternLayout #灵活定义输出格式 具体查看log4j javadoc org.apache.log4j.PatternLayout #d 时间 ….log4j.appender.A1.layout.ConversionPattern=%-d{yyyy-MM-dd HH:mm:ss} [%c]-[%p] %m%n #R 输出到文件 RollingFileAppender的扩展，可以提供一种日志的备份功能。log4j.appender.R=org.apache.log4j.RollingFileAppender #日志文件的名称log4j.appender.R.File=log4j.log #日志文件的大小log4j.appender.R.MaxFileSize=100KB 保存一个备份文件log4j.appender.R.MaxBackupIndex=1 log4j.appender.R.layout=org.apache.log4j.TTCCLayout #log4j.appender.R.layout.ConversionPattern=%-d{yyyy-MM-dd HH:mm:ss} [%c]-[%p] %m%n 122.下面我给出一个在weblogic下使用log4j的配置过程，首先给出这个配置文件的完整信息。 #log4j.rootLogger=INFO,A1,R //这一句指定了日志输出的级别为info,A1和R分别代表日志输出到什么地方。log4j.category.hybl_wshabcm=debug,A1,R //这一句指定了日志具体输出哪个包的信息，以及输出位置log4j.appender.A1=org.apache.log4j.ConsoleAppender //这里指定了日志输出的第一个位置A1是控制台ConsoleAppender/**其中，Log4j提供的appender有以下几种：*org.apache.log4j.ConsoleAppender（控制台），*org.apache.log4j.FileAppender（文件），*org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件），*org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件），*org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）**/log4j.appender.A1.layout=org.apache.log4j.PatternLayout //指定A1的布局模式 /**其中，Log4j提供的layout有以下几种：×org.apache.log4j.HTMLLayout（以HTML表格形式布局），*org.apache.log4j.PatternLayout（可以灵活地指定布局模式），*org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），*org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）*/log4j.appender.A1.layout.ConversionPattern=%-d{yyyy-MM-dd HH:mm:ss,SSS} [%c]-[%p] %m%n //指定日志的输出格式 log4j.appender.R=org.apache.log4j.RollingFileAppender //指定以文件的方式输出日志log4j.appender.R.File=c:/sys.html //文件位置log4j.appender.R.MaxFileSize=500KB //文件最大尺寸log4j.appender.R.MaxBackupIndex=1 //备份数log4j.appender.R.layout=org.apache.log4j.HTMLLayout //文件的格式为Html格式 #log4j.appender.R.layout=org.apache.log4j.PatternLayoutlog4j.appender.R.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss,SSS} [%t] [%c] [%p] - %m%n 1234567\\============================================================ **错误日志发送email**1. 打开log4j.properties文件2. rootLogger加上一个Appender, 即MAIL, 如log4j.rootLogger=ERROR,A1,MAIL3. 配置Appender信息,在文件的末尾加上以下部分 Configuration for receiving e-mails when ERROR messages occur.#自定义的Appenderlog4j.appender.MAIL=org.apache.log4j.net.SMTPAppender #日志的错误级别log4j.appender.MAIL.Threshold=ERROR #缓存文件大小，日志达到512K时发送Emaillog4j.appender.MAIL.BufferSize=512 #发件人log4j.appender.MAIL.From=test@163.com #发送邮件的服务器log4j.appender.MAIL.SMTPHost=smtp.163.com #邮件的标题log4j.appender.MAIL.Subject=Log4J Message #日志邮件的接收者log4j.appender.MAIL.To=test@163.com #日志PatternLayoutlog4j.appender.MAIL.layout=org.apache.log4j.PatternLayout #日志的格式log4j.appender.MAIL.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n 12345678910以上文件皆测试通过，如不通过请查看自己的email发送环境.\\==============================================================================================查看了SMTPAppender.java的源代码，才发现Log4J缺省提供的SMTPAppender并不支持SMTP的认证功能。难道现在匿名的SMTP邮件服务器很多吗？我手头的是Log4J的 1.2.8版本，去logging.apache.org看，发现已经有新的版本了： 1.2.11，呵呵，窃喜。这样的简单、基本的需求Log4J开发组应该已经添加上了吧。下载、查看，再次失望之极！看来只有自己动手添加了。本来应该重新定义一个名字，算做一个自定义Appender吧，但为了使我很多应用中的log4j.properties不用修改过多，就直接在原来的SMTPAppender.java上做了修改。另外一个更重要的原因是： 我认为：这是一个基本的、必须的SMTPAppender应该具有的功能。 1234主要在SMTPAppender.java中添加了如下代码：a. 添加实例变量 private String smtpUsername; private String smtpPassword; 12b. 将 activateOptions() 方法中的 Session session = Session.getInstance(props, null); 12修改为： if(smtpPassword != null &amp;&amp; smtpUsername != null) { // Setup mail server authentication props.put(“mail.smtp.auth”, “true”); // props.put(“mail.transport.protocol”, “smtp”); authenticator = new Authenticator() { protected PasswordAuthentication getPasswordAuthentication() { return new PasswordAuthentication(smtpUsername, smtpPassword); } }; } // Get session Session session = Session.getDefaultInstance(props,authenticator);12c. 添加Set方法 public void setSMTPPassword(String smtpPassword) { this.smtpPassword = smtpPassword; } public void setSMTPUsername(String smtpUsername) { this.smtpUsername = smtpUsername; } 12编译，并重新打包log4j-1.2.8.jar。在应用中替换原log4j-1.2.8.jar包，并修改log4j.properties文件，在SMTPAppender的配置中添加如下两行： log4j.appender.MAIL.SMTPUsername=log4j.appender.MAIL.SMTPPassword= 1234567891011121314151617181920212223242526272829303132OK，现在这个SMTPAppender就可以使用需要用户名、密码验证的SMTP服务器（现在绝大多数SMTP服务器）进行Email报警发送了。* * *log4j详解 根据网络资料整理&gt; &gt; &gt; &gt; 1. 概述&lt;&lt;&lt;&lt; &gt; &gt; &gt; &gt; 1.1. 背景 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 在应用程序中添加日志记录总的来说基于三个目的：监视代码中变量的变化情况，周期性的记录到文件中供其他应用进行统计分析工作；跟踪代码运行时轨迹，作为日后审计的依据；担当集成开发环境中的调试器的作用，向文件或控制台打印代码的调试信息。 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 最普通的做法就是在代码中嵌入许多的打印语句，这些打印语句可以输出到控制台或文件中，比较好的做法就是构造一个日志操作类来封装此类操作，而不是让一系列的打印语句充斥了代码的主体。 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 1.2. Log4j简介 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 在强调可重用组件开发的今天，除了自己从头到尾开发一个可重用的日志操作类外，Apache为我们提供了一个强有力的日志操作包-Log4j。 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Log4j是Apache的一个开放源代码项目，通过使用Log4j，我们可以控制日志信息输送的目的地是控制台、文件、GUI组件、甚至是套接口服务 器、NT的事件记录器、UNIX Syslog守护进程等；我们也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。最令人感兴趣的就 是，这些可以通过一个配置文件来灵活地进行配置，而不需要修改应用的代码。 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 此外，通过Log4j其他语言接口，您可以在C、C+ +、.Net、PL/SQL程序中使用Log4j，其语法和用法与在Java程序中一样，使得多语言分布式系统得到一个统一一致的日志组件模块。而且，通 过使用各种第三方扩展，您可以很方便地将Log4j集成到J2EE、JINI甚至是SNMP应用中。 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 本文介绍的Log4j版本是 1.2.3。作者试图通过一个简单的客户/服务器Java程序例子对比使用与不使用Log4j 1.2.3的差别，并详细讲解了在实践中最常使用Log4j的方法和步骤。在强调可重用组件开发的今天，相信Log4j将会给广大的设计开发人员带来方 便。加入到Log4j的队伍来吧！ &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 2. 一个简单的例子 &lt;&lt;&lt;&lt; 我们先来看一个简单的例子，它是一个用Java实现的客户/服务器网络程序。刚开始我们不使用Log4j，而是使用了一系列的打印语句，然后我们将使用Log4j来实现它的日志功能。这样，大家就可以清楚地比较出前后两个代码的差别。 2.1. 不使用Log4j 2.1.1. 客户程序 package log4j ; import java.io.* ; import java.net.* ; /** * * Client Without Log4j * Description: a sample with log4j * @version 1.0 */ public class ClientWithoutLog4j { /** * * @param args */ public static void main ( String args [] ) { String welcome = null; String response = null; BufferedReader reader = null; PrintWriter writer = null; InputStream in = null; OutputStream out = null; Socket client = null; try { client = new Socket ( “localhost”, 8001 ) ; System.out.println ( “info: Client socket: “ + client ) ; in = client.getInputStream () ; out = client.getOutputStream () ; } catch ( IOException e ) { System.out.println ( “error: IOException : “ + e ) ; System.exit ( 0 ) ; } try{ reader = new BufferedReader( new InputStreamReader ( in ) ) ; writer = new PrintWriter ( new OutputStreamWriter ( out ), true ) ; welcome = reader.readLine () ; System.out.println ( “debug: Server says: ‘“ + welcome + “‘“ ) ; System.out.println ( “debug: HELLO” ) ; writer.println ( “HELLO” ) ; response = reader.readLine () ; System.out.println ( “debug: Server responds: ‘“ + response + “‘“) ; System.out.println ( “debug: HELP” ) ; writer.println ( “HELP” ) ; response = reader.readLine () ; System.out.println ( “debug: Server responds: ‘“ + response + “‘“ ) ; System.out.println ( “debug: QUIT” ) ; writer.println ( “QUIT” ) ; } catch ( IOException e ) { System.out.println ( “warn: IOException in client.in.readln()” ) ; System.out.println ( e ) ; } try{ Thread.sleep ( 2000 ) ; } catch ( Exception ignored ) {} } } 123 2.1.2. 服务器程序 package log4j ; import java.util.* ; import java.io.* ; import java.net.* ; /** * * Server Without Log4j * Description: a sample with log4j * @version 1.0 */ public class ServerWithoutLog4j { final static int SERVER_PORT = 8001 ; // this server’s port /** * * @param args */ public static void main ( String args [] ) { String clientRequest = null; BufferedReader reader = null; PrintWriter writer = null; ServerSocket server = null; Socket socket = null; InputStream in = null; OutputStream out = null; try { server = new ServerSocket ( SERVER_PORT ) ; System.out.println ( “info: ServerSocket before accept: “ + server ) ; System.out.println ( “info: Java server without log4j, on-line!” ) ; // wait for client’s connection socket = server.accept () ; System.out.println ( “info: ServerSocket after accept: “ + server ) ; in = socket.getInputStream () ; out = socket.getOutputStream () ; } catch ( IOException e ) { System.out.println( “error: Server constructor IOException: “ + e ) ; System.exit ( 0 ) ; } reader = new BufferedReader ( new InputStreamReader ( in ) ) ; writer = new PrintWriter ( new OutputStreamWriter ( out ) , true ) ; // send welcome string to client writer.println ( “Java server without log4j, “ + new Date () ) ; while ( true ) { try { // read from client clientRequest = reader.readLine () ; System.out.println ( “debug: Client says: “ + clientRequest ) ; if ( clientRequest.startsWith ( “HELP” ) ) { System.out.println ( “debug: OK!” ) ; writer.println ( “Vocabulary: HELP QUIT” ) ; } else { if ( clientRequest.startsWith ( “QUIT” ) ) { System.out.println ( “debug: OK!” ) ; System.exit ( 0 ) ; } else{ System.out.println ( “warn: Command ‘“ + clientRequest + “‘ not understood.” ) ; writer.println ( “Command ‘“ + clientRequest + “‘ not understood.” ) ; } } } catch ( IOException e ) { System.out.println ( “error: IOException in Server “ + e ) ; System.exit ( 0 ) ; } } } } 12345 2.2. 迁移到Log4j 2.2.1. 客户程序 package log4j ; import java.io.* ; import java.net.* ; // add for log4j: import some package import org.apache.log4j.PropertyConfigurator ; import org.apache.log4j.Logger ; import org.apache.log4j.Level ; /** * * Client With Log4j * Description: a sample with log4j * @version 1.0 */ public class ClientWithLog4j { /* add for log4j: class Logger is the central class in the log4j package. we can do most logging operations by Logger except configuration. getLogger(…): retrieve a logger by name, if not then create for it. / static Logger logger = Logger.getLogger ( ClientWithLog4j.class.getName () ) ; /* * * @param args : configuration file name */ public static void main ( String args [] ) { String welcome = null ; String response = null ; BufferedReader reader = null ; PrintWriter writer = null ; InputStream in = null ; OutputStream out = null ; Socket client = null ; /* add for log4j: class BasicConfigurator can quickly configure the package. print the information to console. */ PropertyConfigurator.configure ( “ClientWithLog4j.properties” ) ; // add for log4j: set the level // logger.setLevel ( ( Level ) Level.DEBUG ) ; try{ client = new Socket( “localhost” , 8001 ) ; // add for log4j: log a message with the info level logger.info ( “Client socket: “ + client ) ; in = client.getInputStream () ; out = client.getOutputStream () ; } catch ( IOException e ) { // add for log4j: log a message with the error level logger.error ( “IOException : “ + e ) ; System.exit ( 0 ) ; } try{ reader = new BufferedReader ( new InputStreamReader ( in ) ) ; writer = new PrintWriter ( new OutputStreamWriter ( out ), true ) ; welcome = reader.readLine () ; // add for log4j: log a message with the debug level logger.debug ( “Server says: ‘“ + welcome + “‘“ ) ; // add for log4j: log a message with the debug level logger.debug ( “HELLO” ) ; writer.println ( “HELLO” ) ; response = reader.readLine () ; // add for log4j: log a message with the debug level logger.debug ( “Server responds: ‘“ + response + “‘“ ) ; // add for log4j: log a message with the debug level logger.debug ( “HELP” ) ; writer.println ( “HELP” ) ; response = reader.readLine () ; // add for log4j: log a message with the debug level logger.debug ( “Server responds: ‘“ + response + “‘“) ; // add for log4j: log a message with the debug level logger.debug ( “QUIT” ) ; writer.println ( “QUIT” ) ; } catch ( IOException e ) { // add for log4j: log a message with the warn level logger.warn ( “IOException in client.in.readln()” ) ; System.out.println ( e ) ; } try { Thread.sleep ( 2000 ) ; } catch ( Exception ignored ) {} } } 123 2.2.2. 服务器程序 package log4j; import java.util.* ; import java.io.* ; import java.net.* ; // add for log4j: import some package import org.apache.log4j.PropertyConfigurator ; import org.apache.log4j.Logger ; import org.apache.log4j.Level ; /** * * Server With Log4j * Description: a sample with log4j * @version 1.0 */ public class ServerWithLog4j { final static int SERVER_PORT = 8001 ; // this server’s port /* add for log4j: class Logger is the central class in the log4j package. we can do most logging operations by Logger except configuration. getLogger(…): retrieve a logger by name, if not then create for it. / static Logger logger = Logger.getLogger ( ServerWithLog4j.class.getName () ) ; /* * * @param args */ public static void main ( String args[]) { String clientRequest = null ; BufferedReader reader = null ; PrintWriter writer = null ; ServerSocket server = null ; Socket socket = null ; InputStream in = null ; OutputStream out = null ; /* add for log4j: class BasicConfigurator can quickly configure the package. print the information to console. */ PropertyConfigurator.configure ( “ServerWithLog4j.properties” ) ; // add for log4j: set the level // logger.setLevel ( ( Level ) Level.DEBUG ) ; try{ server = new ServerSocket ( SERVER_PORT ) ; // add for log4j: log a message with the info level logger.info ( “ServerSocket before accept: “ + server ) ; // add for log4j: log a message with the info level logger.info ( “Java server with log4j, on-line!” ) ; // wait for client’s connection socket = server.accept() ; // add for log4j: log a message with the info level logger.info ( “ServerSocket after accept: “ + server ) ; in = socket.getInputStream() ; out = socket.getOutputStream() ; } catch ( IOException e ) { // add for log4j: log a message with the error level logger.error ( “Server constructor IOException: “ + e ) ; System.exit ( 0 ) ; } reader = new BufferedReader ( new InputStreamReader ( in ) ) ; writer = new PrintWriter ( new OutputStreamWriter ( out ), true ) ; // send welcome string to client writer.println ( “Java server with log4j, “ + new Date () ) ; while ( true ) { try { // read from client clientRequest = reader.readLine () ; // add for log4j: log a message with the debug level logger.debug ( “Client says: “ + clientRequest ) ; if ( clientRequest.startsWith ( “HELP” ) ) { // add for log4j: log a message with the debug level logger.debug ( “OK!” ) ; writer.println ( “Vocabulary: HELP QUIT” ) ; } else { if ( clientRequest.startsWith ( “QUIT” ) ) { // add for log4j: log a message with the debug level logger.debug ( “OK!” ) ; System.exit ( 0 ) ; } else { // add for log4j: log a message with the warn level logger.warn ( “Command ‘“ + clientRequest + “‘ not understood.” ) ; writer.println ( “Command ‘“ + clientRequest + “‘ not understood.” ) ; } } } catch ( IOException e ) { // add for log4j: log a message with the error level logger.error( “IOException in Server “ + e ) ; System.exit ( 0 ) ; } } } } 12345 2.2.3. 配置文件 2.2.3.1. 客户程序配置文件 log4j.rootLogger=INFO, A1 log4j.appender.A1=org.apache.log4j.ConsoleAppender log4j.appender.A1.layout=org.apache.log4j.PatternLayout log4j.appender.A1.layout.ConversionPattern=%-4r %-5p [%t] %37c %3x - %m%n 123 2.2.3.2. 服务器程序配置文件 log4j.rootLogger=INFO, A1 log4j.appender.A1=org.apache.log4j.ConsoleAppender log4j.appender.A1.layout=org.apache.log4j.PatternLayout log4j.appender.A1.layout.ConversionPattern=%-4r %-5p [%t] %37c %3x - %m%n 1234567 2.3. 比较 比较这两个应用可以看出，采用Log4j进行日志操作的整个过程相当简单明了，与直接使用System.out.println语句进行日志信息输出的 方式相比，基本上没有增加代码量，同时能够清楚地理解每一条日志信息的重要程度。通过控制配置文件，我们还可以灵活地修改日志信息的格式，输出目的地等等 方面，而单纯依靠System.out.println语句，显然需要做更多的工作。&gt; &gt; &gt; &gt; 3 . Log4j日志管理系统简单使用说明 &lt;&lt;&lt;&lt; 通常，我们都提供一个名为 log4j.properties的文件，在第一次调用到Log4J时，Log4J会在类路径（../web-inf/class/当然也可以放到其它任何目录，只要该目录被包含到类路径中即可）中定位这个文件，并读入这个文件完成的配置。这个配置文件告 诉Log4J以什么样的格式、把什么样的信息、输出到什么地方。 123456789101112 Log4j有三个主要的组件：Loggers(记录器)，Appenders(输出源)和Layouts(布局)，这里可简单理解为日志类别，日志要输出的地方和日志以何种形式输出。综合使用这三个组件可以轻松的记录信息的类型和级别，并可以在运行时控制日志输出的样式和位置。下面对三个组件分别进行说明： 1、 Loggers Loggers组件在此系统中被分为五个级别：DEBUG、INFO、WARN、ERROR和FATAL。这五个级别是有顺序的，DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，分别用来指定这条日志信息的重要程度,明白这一点很重要，这里Log4j有一个规则：假设Loggers级别为P，如果在Loggers中发生了一个级别Q比P高，则可以启动，否则屏蔽掉。 假设你定义的级别是info，那么error和warn的日志可以显示而比他低的debug信息就不显示了。 Java程序举例来说： //建立Logger的一个实例，命名为“com.foo” Logger logger = Logger.getLogger(“com.foo”); //”com.foo”是实例进行命名，也可以任意 //设置logger的级别。通常不在程序中设置logger的级别。一般在配置文件中设置。 logger.setLevel(Level.INFO); Logger barlogger = Logger.getLogger(“com.foo.Bar”); //下面这个请求可用，因为WARN &gt;= INFO logger.warn(“Low fuel level.”); //下面这个请求不可用，因为DEBUG &lt; INFO logger.debug(“Starting search for nearest gas station.”); //命名为“com.foo.bar”的实例barlogger会继承实例“com.foo”的级别。因此，下面这个请求可用，因为INFO &gt;= INFO barlogger.info(“Located nearest gas station.”); //下面这个请求不可用，因为DEBUG &lt; INFO barlogger.debug(“Exiting gas station search”); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137 这里“是否可用”的意思是能否输出Logger信息。 在对Logger实例进行命名时，没有限制，可以取任意自己感兴趣的名字。一般情况下建议以类的所在位置来命名Logger实例，这是目前来讲比较有效的Logger命名方式。这样可以使得每个类建立自己的日志信息，便于管理。比如： static Logger logger = Logger.getLogger(ClientWithLog4j.class.getName()); 2、Appenders 禁用与使用日志请求只是Log4j其中的一个小小的地方，Log4j日志系统允许把日志输出到不同的地方，如控制台（Console）、文件（Files）、根据天数或者文件大小产生新的文件、以流的形式发送到其它地方等等。 其语法表示为： org.apache.log4j.ConsoleAppender（控制台） org.apache.log4j.FileAppender（文件） org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件） org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件） org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） 配置时使用方式为： log4j.appender.appenderName = fully.qualified.name.of.appender.class log4j.appender.appenderName.option1 = value1 … log4j.appender.appenderName.option = valueN 这样就为日志的输出提供了相当大的便利。 3、Layouts 有时用户希望根据自己的喜好格式化自己的日志输出。Log4j可以在Appenders的后面附加Layouts来完成这个功能。Layouts提供了 四种日志输出样式，如根据HTML样式、自由指定样式、包含日志级别与信息的样式和包含日志时间、线程、类别等信息的样式等等。 其语法表示为： org.apache.log4j.HTMLLayout（以HTML表格形式布局）， org.apache.log4j.PatternLayout（可以灵活地指定布局模式）， org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）， org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） 配置时使用方式为： log4j.appender.appenderName.layout =fully.qualified.name.of.layout.class log4j.appender.appenderName.layout.option1 = value1 … log4j.appender.appenderName.layout.option = valueN&gt; &gt; &gt; &gt; 4 . Log4j的配置 &lt;&lt;&lt;&lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 以上是从原理方面说明Log4j的使用方法，在具体Java编程使用Log4j可以参照以下示例： &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 1、 建立Logger实例： &gt; &gt; &gt; &gt; 语法表示：public static Logger getLogger( String name) &gt; &gt; &gt; &gt; 实际使用：static Logger logger = Logger.getLogger(ServerWithLog4j.class.getName ()) ; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 2、 读取配置文件： &gt; &gt; &gt; &gt; 获得了Logger的实例之后，接下来将配置Log4j使用环境： &gt; &gt; &gt; &gt; 语法表示： &gt; &gt; &gt; &gt; BasicConfigurator.configure()：自动快速地使用缺省Log4j环境。 &gt; &gt; &gt; &gt; PropertyConfigurator.configure(String configFilename)：读取使用Java的特性文件编写的配置文件。 &gt; &gt; &gt; &gt; DOMConfigurator.configure(String filename)：读取XML形式的配置文件。 &gt; &gt; &gt; &gt; 实际使用： &gt; &gt; &gt; &gt; PropertyConfigurator.configure(“ServerWithLog4j.properties”); &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 3、 插入日志信息 &gt; &gt; &gt; &gt; 完成了以上连个步骤以后，下面就可以按日志的不同级别插入到你要记录日志的任何地方了。 &gt; &gt; &gt; &gt; 语法表示： &gt; &gt; &gt; &gt; Logger.debug(Object message);//调试信息 &gt; &gt; &gt; &gt; Logger.info(Object message);//一般信息 &gt; &gt; &gt; &gt; Logger.warn(Object message);//警告信息 &gt; &gt; &gt; &gt; Logger.error(Object message);//错误信息 &gt; &gt; &gt; &gt; Logger.fatal(Object message);//致命错误信息 实际使用：logger.info(“ServerSocket before accept: ” + server); &gt;&gt;&gt;&gt; 5. 配置过程 &lt;&lt;&lt;&lt; 在实际编程时，要使Log4j真正在系统中运行事先还要对配置文件进行定义。定义步骤就是对Logger、Appender及Layout的分别使用。 Log4j支持两种配置文件格式，一种是XML格式的文件，一种是java properties（key=value）【Java特性文件（键=值）】。下面我们介绍使用Java特性文件做为配置文件的方法 具体如下： 1、配置根Logger，其语法为： log4j.rootLogger = \\[ level \\] , appenderName1, appenderName2, … level : 是日志记录的优先级，分为OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者您定义的级别。Log4j建议只使用四个级别，优先级从高到低分别是ERROR、WARN、INFO、DEBUG。通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关。比如在这里定 义了INFO级别，则应用程序中所有DEBUG级别的日志信息将不被打印出来。 appenderName:就是指定日志信息输出到哪个地方。您可以同时指定多个输出目的地。 例如：log4j.rootLogger＝info,A1,B2,C3 2、配置日志信息输出目的地，其语法为： log4j.appender.appenderName = fully.qualified.name.of.appender.class // “fully.qualified.name.of.appender.class” 可以指定下面五个目的地中的一个： 1.org.apache.log4j.ConsoleAppender（控制台） 2.org.apache.log4j.FileAppender（文件） 3.org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件） 4.org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件） 5.org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） 1.ConsoleAppender选项 Threshold=WARN:指定日志消息的输出最低层次。 ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。 Target=System.err：默认情况下是：System.out,指定输出控制台 2.FileAppender 选项 Threshold=WARN:指定日志消息的输出最低层次。 ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。 File=mylog.txt:指定消息输出到mylog.txt文件。 Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。 3.DailyRollingFileAppender 选项 Threshold=WARN:指定日志消息的输出最低层次。 ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。 File=mylog.txt:指定消息输出到mylog.txt文件。 Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。 DatePattern=’.’yyyy-ww:每周滚动一次文件，即每周产生一个新的文件。当然也可以指定按月、周、天、时和分。即对应的格式如下： 1)’.’yyyy-MM: 每月 2)’.’yyyy-ww: 每周 3)’.’yyyy-MM-dd: 每天 4)’.’yyyy-MM-dd-a: 每天两次 5)’.’yyyy-MM-dd-HH: 每小时 6)’.’yyyy-MM-dd-HH-mm: 每分钟 4.RollingFileAppender 选项 Threshold=WARN:指定日志消息的输出最低层次。 ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。 File=mylog.txt:指定消息输出到mylog.txt文件。 Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。 MaxFileSize=100KB: 后缀可以是KB, MB 或者是 GB. 在日志文件到达该大小时，将会自动滚动，即将原来的内容移到mylog.log.1文件。 MaxBackupIndex=2:指定可以产生的滚动文件的最大数。实际应用： log4j.appender.A1=org.apache.log4j.ConsoleAppender //这里指定了日志输出的第一个位置A1是控制台ConsoleAppender 3、配置日志信息的格式，其语法为： A. log4j.appender.appenderName.layout = fully.qualified.name.of.layout.class “fully.qualified.name.of.layout.class” 可以指定下面4个格式中的一个： 1.org.apache.log4j.HTMLLayout（以HTML表格形式布局）， 2.org.apache.log4j.PatternLayout（可以灵活地指定布局模式）， 3.org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）， 4.org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） 1.HTMLLayout 选项 LocationInfo=true:默认值是false,输出java文件名称和行号 Title=my app file: 默认值是 Log4J Log Messages. 2.PatternLayout 选项 ConversionPattern=%m%n :指定怎样格式化指定的消息。 3.XMLLayout 选项 LocationInfo=true:默认值是false,输出java文件和行号 实际应用： log4j.appender.A1.layout=org.apache.log4j.PatternLayout B. log4j.appender.A1.layout.ConversionPattern=%-4r %-5p %d{yyyy-MM-dd HH:mm:ssS} %c %m%n 这里需要说明的就是日志信息格式中几个符号所代表的含义： 123456789101112131415161718192021222324252627282930313233 －X号: X信息输出时左对齐； %p: 输出日志信息优先级，即DEBUG，INFO，WARN，ERROR，FATAL, %d: 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d&#123;yyy MMM dd HH:mm:ss,SSS&#125;，输出类似：2002年10月18日 22：10：28，921 %r: 输出自应用启动到输出该log信息耗费的毫秒数 %c: 输出日志信息所属的类目，通常就是所在类的全名 %t: 输出产生该日志事件的线程名 %l: 输出日志事件的发生位置，相当于%C.%M(%F:%L)的组合,包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java:10) %x: 输出和当前线程相关联的NDC(嵌套诊断环境),尤其用到像java servlets这样的多客户多线程的应用中。 %%: 输出一个”%”字符 %F: 输出日志消息产生时所在的文件名称 %L: 输出代码中的行号 %m: 输出代码中指定的消息,产生的日志具体信息 %n: 输出一个回车换行符，Windows平台为”\\\\r\\\\n”，Unix平台为”\\\\n”输出日志信息换行 可以在%与模式字符之间加上修饰符来控制其最小宽度、最大宽度、和文本的对齐方式。如： 1)%20c：指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，默认的情况下右对齐。 2)%-20c:指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，”-“号指定左对齐。 3)%.30c:指定输出category的名称，最大的宽度是30，如果category的名称大于30的话，就会将左边多出的字符截掉，但小于30的话也不会有空格。 4)%20.30c:如果category的名称小于20就补空格，并且右对齐，如果其名称长于30字符，就从左边交远销出的字符截掉。 这里上面三个步骤是对前面Log4j组件说明的一个简化；下面给出一个具体配置例子，在程序中可以参照执行： log4j.rootLogger=INFO,A1，B2 log4j.appender.A1=org.apache.log4j.ConsoleAppender log4j.appender.A1.layout=org.apache.log4j.PatternLayout log4j.appender.A1.layout.ConversionPattern=%-4r %-5p %d&#123;yyyy-MM-dd HH:mm:ssS&#125; %c %m%n 根据上面的日志格式，某一个程序的输出结果如下： 0 INFO 2003-06-13 13:23:46968 ClientWithLog4j Client socket: Socket\\[addr=localhost/127.0.0.1,port=8002,localport=2014\\] 16 DEBUG 2003-06-13 13:23:46984 ClientWithLog4j Server says: ‘Java server with log4j, Fri Jun 13 13:23:46 CST 2003’ 16 DEBUG 2003-06-13 13:23:46984 ClientWithLog4j GOOD 16 DEBUG 2003-06-13 13:23:46984 ClientWithLog4j Server responds: ‘Command ‘HELLO’ not understood.’ 16 DEBUG 2003-06-13 13:23:46984 ClientWithLog4j HELP 16 DEBUG 2003-06-13 13:23:46984 ClientWithLog4j Server responds: ‘Vocabulary: HELP QUIT’ 16 DEBUG 2003-06-13 13:23:46984 ClientWithLog4j QUIT 当输出信息于回滚文件时 log4j.appender.ROLLING_FILE=org.apache.log4j.RollingFileAppender //指定以文件的方式输出日志 log4j.appender.ROLLING_FILE.Threshold=ERROR log4j.appender.ROLLING_FILE.File=rolling.log //文件位置,也可以用变量${java.home}、rolling.log log4j.appender.ROLLING_FILE.Append=true log4j.appender.ROLLING_FILE.MaxFileSize=10KB //文件最大尺寸 log4j.appender.ROLLING_FILE.MaxBackupIndex=1 //备份数 log4j.appender.ROLLING_FILE.layout=org.apache.log4j.PatternLayout log4j.appender.ROLLING_FILE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990××××××××××××××××××××××××××××××××××××××××××××××××&gt; &gt; &gt; &gt; 1. Log4j比较全面的配置 &lt;&lt;&lt;&lt;LOG4J的配置之简单使它遍及于越来越多的应用中了：Log4J配置文件实现了输出到控制台、文件、回滚文件、发送日志邮件、输出到数据库日志表、自定义标签等全套功能。择其一二使用就够用了，log4j.rootLogger=DEBUG,CONSOLE,A1,im log4j.addivity.org.apache=true\\# 应用于控制台log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender log4j.appender.Threshold=DEBUG log4j.appender.CONSOLE.Target=System.out log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout log4j.appender.CONSOLE.layout.ConversionPattern=\\[framework\\] %d - %c -%-4r \\[%t\\] %-5p %c %x - %m%n #log4j.appender.CONSOLE.layout.ConversionPattern=\\[start\\]%d&#123;DATE&#125;\\[DATE\\]%n%p\\[PRIORITY\\]%n%x\\[NDC\\]%n%t\\[THREAD\\] n%c\\[CATEGORY\\]%n%m\\[MESSAGE\\]%n%n#应用于文件log4j.appender.FILE=org.apache.log4j.FileAppender log4j.appender.FILE.File=file.log log4j.appender.FILE.Append=false log4j.appender.FILE.layout=org.apache.log4j.PatternLayout log4j.appender.FILE.layout.ConversionPattern=\\[framework\\] %d - %c -%-4r \\[%t\\] %-5p %c %x - %m%n \\# Use this layout for LogFactor 5 analysis\\# 应用于文件回滚log4j.appender.ROLLING\\_FILE=org.apache.log4j.RollingFileAppender log4j.appender.ROLLING\\_FILE.Threshold=ERROR log4j.appender.ROLLING\\_FILE.File=rolling.log //文件位置,也可以用变量$&#123;java.home&#125;、rolling.log log4j.appender.ROLLING\\_FILE.Append=true //true:添加 false:覆盖 log4j.appender.ROLLING\\_FILE.MaxFileSize=10KB //文件最大尺寸 log4j.appender.ROLLING\\_FILE.MaxBackupIndex=1 //备份数 log4j.appender.ROLLING\\_FILE.layout=org.apache.log4j.PatternLayout log4j.appender.ROLLING\\_FILE.layout.ConversionPattern=\\[framework\\] %d - %c -%-4r \\[%t\\] %-5p %c %x - %m%n#应用于socket log4j.appender.SOCKET=org.apache.log4j.RollingFileAppender log4j.appender.SOCKET.RemoteHost=localhost log4j.appender.SOCKET.Port=5001 log4j.appender.SOCKET.LocationInfo=true \\# Set up for Log Facter 5 log4j.appender.SOCKET.layout=org.apache.log4j.PatternLayout log4j.appender.SOCET.layout.ConversionPattern=\\[start\\]%d&#123;DATE&#125;\\[DATE\\]%n%p\\[PRIORITY\\]%n%x\\[NDC\\]%n%t\\[THREAD\\]%n%c\\[CATEGORY\\]%n%m\\[MESSAGE\\]%n%n\\# Log Factor 5 Appender log4j.appender.LF5\\_APPENDER=org.apache.log4j.lf5.LF5Appender log4j.appender.LF5\\_APPENDER.MaxNumberOfRecords=2000\\# 发送日志给邮件log4j.appender.MAIL=org.apache.log4j.net.SMTPAppender log4j.appender.MAIL.Threshold=FATAL log4j.appender.MAIL.BufferSize=10 log4j.appender.MAIL.From=web@www.wuset.com log4j.appender.MAIL.SMTPHost=www.wusetu.com log4j.appender.MAIL.Subject=Log4J Message log4j.appender.MAIL.To=web@www.wusetu.com log4j.appender.MAIL.layout=org.apache.log4j.PatternLayout log4j.appender.MAIL.layout.ConversionPattern=\\[framework\\] %d - %c -%-4r \\[%t\\] %-5p %c %x - %m%n\\# 用于数据库 log4j.appender.DATABASE=org.apache.log4j.jdbc.JDBCAppender log4j.appender.DATABASE.URL=jdbc:mysql://localhost:3306/test log4j.appender.DATABASE.driver=com.mysql.jdbc.Driver log4j.appender.DATABASE.user=root log4j.appender.DATABASE.password= log4j.appender.DATABASE.sql=INSERT INTO LOG4J (Message) VALUES (‘\\[framework\\] %d - %c -%-4r \\[%t\\] %-5p %c %x - %m%n’) log4j.appender.DATABASE.layout=org.apache.log4j.PatternLayout log4j.appender.DATABASE.layout.ConversionPattern=\\[framework\\] %d - %c -%-4r \\[%t\\] %-5p %c %x - %m%nlog4j.appender.A1=org.apache.log4j.DailyRollingFileAppender log4j.appender.A1.File=SampleMessages.log4j log4j.appender.A1.DatePattern=yyyyMMdd-HH’.log4j’ log4j.appender.A1.layout=org.apache.log4j.xml.XMLLayout#自定义Appenderlog4j.appender.im = net.cybercorlin.util.logger.appender.IMAppenderlog4j.appender.im.host = mail.cybercorlin.net log4j.appender.im.username = username log4j.appender.im.password = password log4j.appender.im.recipient = corlin@cybercorlin.netlog4j.appender.im.layout=org.apache.log4j.PatternLayout log4j.appender.im.layout.ConversionPattern =\\[framework\\] %d - %c -%-4r \\[%t\\] %-5p %c %x - %m%n","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://zhoumoon.github.io/tags/Java/"}]},{"title":"为什么 Java 中只有值传递？","slug":"为什么 Java 中只有值传递？","date":"2019-09-11T11:23:12.000Z","updated":"2021-02-08T08:14:20.157Z","comments":false,"path":"2019/09/11/为什么 Java 中只有值传递？/","link":"","permalink":"http://zhoumoon.github.io/2019/09/11/为什么 Java 中只有值传递？/","excerpt":"","text":"首先回顾一下在程序设计语言中有关将参数传递给方法（或函数）的一些专业术语。按值调用(call by value)表示方法接收的是调用者提供的值，而按引用调用（call by reference)表示方法接收的是调用者提供的变量地址。一个方法可以修改传递引用所对应的变量值，而不能修改传递值调用所对应的变量值。 它用来描述各种程序设计语言（不只是Java)中方法参数传递方式。 Java程序设计语言总是采用按值调用。也就是说，方法得到的是所有参数值的一个拷贝，也就是说，方法不能修改传递给它的任何参数变量的内容。 下面通过 3 个例子来给大家说明 example 1123456789101112131415161718public static void main(String[] args) &#123; int num1 = 10; int num2 = 20; swap(num1, num2); System.out.println(\"num1 = \" + num1); System.out.println(\"num2 = \" + num2);&#125;public static void swap(int a, int b) &#123; int temp = a; a = b; b = temp; System.out.println(\"a = \" + a); System.out.println(\"b = \" + b);&#125; 结果： 1234a = 20b = 10num1 = 10num2 = 20 解析： 在swap方法中，a、b的值进行交换，并不会影响到 num1、num2。因为，a、b中的值，只是从 num1、num2 的复制过来的。也就是说，a、b相当于num1、num2 的副本，副本的内容无论怎么修改，都不会影响到原件本身。 通过上面例子，我们已经知道了一个方法不能修改一个基本数据类型的参数，而对象引用作为参数就不一样，请看 example2. example 21234567891011public static void main(String[] args) &#123; int[] arr = &#123; 1, 2, 3, 4, 5 &#125;; System.out.println(arr[0]); change(arr); System.out.println(arr[0]);&#125;public static void change(int[] array) &#123; // 将数组的第一个元素变为0 array[0] = 0;&#125; 结果： 1210 解析： array 被初始化 arr 的拷贝也就是一个对象的引用，也就是说 array 和 arr 指向的时同一个数组对象。 因此，外部对引用对象的改变会反映到所对应的对象上。 通过 example2 我们已经看到，实现一个改变对象参数状态的方法并不是一件难事。理由很简单，方法得到的是对象引用的拷贝，对象引用及其他的拷贝同时引用同一个对象。 很多程序设计语言（特别是，C++和Pascal)提供了两种参数传递的方式：值调用和引用调用。有些程序员（甚至本书的作者）认为Java程序设计语言对对象采用的是引用调用，实际上，这种理解是不对的。由于这种误解具有一定的普遍性，所以下面给出一个反例来详细地阐述一下这个问题。 example 312345678910111213141516171819public class Test &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Student s1 = new Student(\"小张\"); Student s2 = new Student(\"小李\"); Test.swap(s1, s2); System.out.println(\"s1:\" + s1.getName()); System.out.println(\"s2:\" + s2.getName()); &#125; public static void swap(Student x, Student y) &#123; Student temp = x; x = y; y = temp; System.out.println(\"x:\" + x.getName()); System.out.println(\"y:\" + y.getName()); &#125;&#125; 结果： 1234x:小李y:小张s1:小张s2:小李 解析： 交换之前： 交换之后： 通过上面两张图可以很清晰的看出： 方法并没有改变存储在变量 s1 和 s2 中的对象引用。swap方法的参数x和y被初始化为两个对象引用的拷贝，这个方法交换的是这两个拷贝 总结Java程序设计语言对对象采用的不是引用调用，实际上，对象引用是按值传递的。 下面再总结一下Java中方法参数的使用情况： 一个方法不能修改一个基本数据类型的参数（即数值型或布尔型）。 一个方法可以改变一个对象参数的状态。 一个方法不能让对象参数引用一个新的对象。 参考：《Java核心技术卷Ⅰ》基础知识第十版第四章4.5小节 二 ==与equals(重要)== : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。(基本数据类型==比较的是值，引用数据类型==比较的是内存地址) equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况： 情况1：类没有覆盖equals()方法。则通过equals()比较该类的两个对象时，等价于通过“==”比较这两个对象。 情况2：类覆盖了equals()方法。一般，我们都覆盖equals()方法来两个对象的内容相等；若它们的内容相等，则返回true(即，认为这两个对象相等)。 举个例子： 1234567891011121314151617public class test1 &#123; public static void main(String[] args) &#123; String a = new String(\"ab\"); // a 为一个引用 String b = new String(\"ab\"); // b为另一个引用,对象的内容一样 String aa = \"ab\"; // 放在常量池中 String bb = \"ab\"; // 从常量池中查找 if (aa == bb) // true System.out.println(\"aa==bb\"); if (a == b) // false，非同一对象 System.out.println(\"a==b\"); if (a.equals(b)) // true System.out.println(\"aEQb\"); if (42 == 42.0) &#123; // true System.out.println(\"true\"); &#125; &#125;&#125; 说明： String中的equals方法是被重写过的，因为object的equals方法是比较的对象的内存地址，而String的equals方法比较的是对象的值。 当创建String类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个String对象。 三 hashCode与equals（重要）面试官可能会问你：“你重写过 hashcode 和 equals 么，为什么重写equals时必须重写hashCode方法？” hashCode（）介绍hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 定义在JDK的Object.java中，这就意味着Java中的任何类都包含有hashCode() 函数。另外需要注意的是： Object 的 hashcode 方法是本地方法，也就是用 c 语言或 c++ 实现的，该方法通常用来将对象的 内存地址 转换为整数之后返回。 1234567891011121314151617/** * Returns a hash code value for the object. This method is * supported for the benefit of hash tables such as those provided by * &#123;@link java.util.HashMap&#125;. * &lt;p&gt; * As much as is reasonably practical, the hashCode method defined by * class &#123;@code Object&#125; does return distinct integers for distinct * objects. (This is typically implemented by converting the internal * address of the object into an integer, but this implementation * technique is not required by the * Java&amp;trade; programming language.) * * @return a hash code value for this object. * @see java.lang.Object#equals(java.lang.Object) * @see java.lang.System#identityHashCode */public native int hashCode(); 散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象） 为什么要有hashCode我们以“HashSet如何检查重复”为例子来说明为什么要有hashCode： 当你把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他已经加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的Java启蒙书《Head fist java》第二版）。这样我们就大大减少了equals的次数，相应就大大提高了执行速度。 hashCode（）与equals（）的相关规定 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个对象分别调用equals方法都返回true 两个对象有相同的hashcode值，它们也不一定是相等的 因此，equals方法被覆盖过，则hashCode方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） 为什么两个对象有相同的hashcode值，它们也不一定是相等的？在这里解释一位小伙伴的问题。以下内容摘自《Head Fisrt Java》。 因为hashCode() 所使用的杂凑算法也许刚好会让多个对象传回相同的杂凑值。越糟糕的杂凑算法越容易碰撞，但这也与数据值域分布的特性有关（所谓碰撞也就是指的是不同的对象得到相同的 hashCode）。 我们刚刚也提到了 HashSet,如果 HashSet 在对比的时候，同样的 hashcode 有多个对象，它会使用 equals() 来判断是否真的相同。也就是说 hashcode 只是用来缩小查找成本。 参考： https://blog.csdn.net/zhzhao999/article/details/53449504 https://www.cnblogs.com/skywang12345/p/3324958.html https://www.cnblogs.com/Eason-S/p/5524837.html","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://zhoumoon.github.io/tags/Java/"}]},{"title":"干货：计算机网络知识总结","slug":"干货：计算机网络知识总结","date":"2019-09-11T04:03:11.000Z","updated":"2021-02-08T08:14:20.165Z","comments":false,"path":"2019/09/11/干货：计算机网络知识总结/","link":"","permalink":"http://zhoumoon.github.io/2019/09/11/干货：计算机网络知识总结/","excerpt":"","text":"目录结构 1. 计算机概述 2. 物理层 3. 数据链路层 4. 网络层 5. 运输层 6. 应用层一计算机概述（1），基本术语 结点 （node）：网络中的结点可以是计算机，集线器，交换机或路由器等。 链路（link ）：从一个结点到另一个结点的一段物理线路。中间没有任何其他交点。 主机（host）：连接在因特网上的计算机. ISP（Internet Service Provider）：因特网服务提供者（提供商）. IXP（Internet eXchange Point）：互联网交换点IXP的主要作用就是允许两个网络直接相连并交换分组，而不需要再通过第三个网络来转发分组。. RFC(Request For Comments)意思是“请求评议”，包含了关于Internet几乎所有的重要的文字资料。 广域网WAN（Wide Area Network）任务是通过长距离运送主机发送的数据 城域网MAN（Metropolitan Area Network）用来讲多个局域网进行互连 局域网LAN（Local Area Network）学校或企业大多拥有多个互连的局域网 个人区域网PAN（Personal Area Network）在个人工作的地方把属于个人使用的电子设备用无线技术连接起来的网络 端系统（end system）：处在因特网边缘的部分即是连接在因特网上的所有的主机. 分组（packet ）：因特网中传送的数据单元。由首部header和数据段组成。分组又称为包，首部可称为包头。 存储转发（store and forward ）:路由器收到一个分组，先存储下来，再检查其首部，查找转发表，按照首部中的目的地址，找到合适的接口转发出去。 带宽（bandwidth）：在计算机网络中，表示在单位时间内从网络中的某一点到另一点所能通过的“最高数据率”。常用来表示网络的通信线路所能传送数据的能力。单位是“比特每秒”，记为b/s。 吞吐量（throughput ）：表示在单位时间内通过某个网络（或信道、接口）的数据量。吞吐量更经常地用于对现实世界中的网络的一种测量，以便知道实际上到底有多少数据量能够通过网络。吞吐量受网络的带宽或网络的额定速率的限制。（2），重要知识点总结 1，计算机网络（简称网络）把许多计算机连接在一起，而互联网把许多网络连接在一起，是网络的网络。 2，小写字母i开头的internet（互联网）是通用名词，它泛指由多个计算机网络相互连接而成的网络。在这些网络之间的通信协议（即通信规则）可以是任意的。 大写字母I开头的Internet（互联网）是专用名词，它指全球最大的，开放的，由众多网络相互连接而成的特定的互联网，并采用TCP/IP协议作为通信规则，其前身为ARPANET。Internet的推荐译名为因特网，现在一般流行称为互联网。 3，路由器是实现分组交换的关键构件，其任务是转发收到的分组，这是网络核心部分最重要的功能。分组交换采用存储转发技术，表示把一个报文（要发送的整块数据）分为几个分组后再进行传送。在发送报文之前，先把较长的报文划分成为一个个更小的等长数据段。在每个数据端的前面加上一些由必要的控制信息组成的首部后，就构成了一个分组。分组又称为包。分组是在互联网中传送的数据单元，正是由于分组的头部包含了诸如目的地址和源地址等重要控制信息，每一个分组才能在互联网中独立的选择传输路径，并正确地交付到分组传输的终点。 4，互联网按工作方式可划分为边缘部分和核心部分。主机在网络的边缘部分，其作用是进行信息处理。由大量网络和连接这些网络的路由器组成核心部分，其作用是提供连通性和交换。 5，计算机通信是计算机中进程（即运行着的程序）之间的通信。计算机网络采用的通信方式是客户-服务器方式（C/S方式）和对等连接方式（P2P方式）。 6，客户和服务器都是指通信中所涉及的应用进程。客户是服务请求方，服务器是服务提供方。 7，按照作用范围的不同，计算机网络分为广域网WAN，城域网MAN，局域网LAN，个人区域网PAN。 8，计算机网络最常用的性能指标是：速率，带宽，吞吐量，时延（发送时延，处理时延，排队时延），时延带宽积，往返时间和信道利用率。 9，网络协议即协议，是为进行网络中的数据交换而建立的规则。计算机网络的各层以及其协议集合，称为网络的体系结构。 10，五层体系结构由应用层，运输层，网络层（网际层），数据链路层，物理层组成。运输层最主要的协议是TCP和UDP协议，网络层最重要的协议是IP协议。 二物理层（1），基本术语数据（data）：运送消息的实体。信号（signal）：数据的电气的或电磁的表现。或者说信号是适合在传输介质上传输的对象。码元（ code）： 在使用时间域（或简称为时域）的波形来表示数字信号时，代表不同离散数值的基本波形。单工（simplex ）：只能有一个方向的通信而没有反方向的交互。半双工（half duplex ）：通信的双方都可以发送信息，但不能双方同时发送(当然也就不能同时接收)。全双工（full duplex）： 通信的双方可以同时发送和接收信息。奈氏准则：在任何信道中，码元的传输的效率是有上限的，传输速率超过此上限，就会出现严重的码间串扰问题，使接收端对码元的判决（即识别）成为不可能。基带信号（baseband signal）：来自信源的信号。指没有经过调制的数字信号或模拟信号。 带通（频带）信号（bandpass signal）：把基带信号经过载波调制后，把信号的频率范围搬移到较高的频段以便在信道中传输（即仅在一段频率范围内能够通过信道），这里调制过后的信号就是带通信号。 调制（modulation ）：对信号源的信息进行处理后加到载波信号上，使其变为适合在信道传输的形式的过程。信噪比（signal-to-noise ratio ）：指信号的平均功率和噪声的平均功率之比，记为S/N。信噪比（dB）=10*log10（S/N）信道复用（channel multiplexing ）：指多个用户共享同一个信道。（并不一定是同时）比特率（bit rate ）：单位时间（每秒）内传送的比特数。波特率（baud rate）：单位时间载波调制状态改变的次数。针对数据信号对载波的调制速率。复用（multiplexing）：共享信道的方法ADSL（Asymmetric Digital Subscriber Line ）： 非对称数字用户线。光纤同轴混合网（HFC网）:在目前覆盖范围很广的有线电视网的基础上开发的一种居民宽带接入网（2），重要知识点总结 1，物理层的主要任务就是确定与传输媒体接口有关的一些特性，如机械特性，电气特性，功能特性，过程特性。 2，一个数据通信系统可划分为三大部分，即源系统，传输系统，目的系统。源系统包括源点（或源站，信源）和发送器，目的系统包括接收器和终点。 3，通信的目的是传送消息。如话音，文字，图像等都是消息，数据是运送消息的实体。信号则是数据的电器或电磁的表现。 4，根据信号中代表消息的参数的取值方式不同，信号可分为模拟信号（或连续信号）和数字信号（或离散信号）。在使用时间域（简称时域）的波形表示数字信号时，代表不同离散数值的基本波形称为码元。 5，根据双方信息交互的方式，通信可划分为单向通信（或单工通信），双向交替通信（或半双工通信），双向同时通信（全双工通信）。 6，来自信源的信号称为基带信号。信号要在信道上传输就要经过调制。调制有基带调制和带通调制之分。最基本的带通调制方法有调幅，调频和调相。还有更复杂的调制方法，如正交振幅调制。 7，要提高数据在信道上的传递速率，可以使用更好的传输媒体，或使用先进的调制技术。但数据传输速率不可能任意被提高。 8，传输媒体可分为两大类，即导引型传输媒体（双绞线，同轴电缆，光纤）和非导引型传输媒体（无线，红外，大气激光）。 9，为了有效利用光纤资源，在光纤干线和用户之间广泛使用无源光网络PON。无源光网络无需配备电源，其长期运营成本和管理成本都很低。最流行的无源光网络是以太网无源光网络EPON和吉比特无源光网络GPON。 （3），最重要的知识点①，物理层的任务 透明地传送比特流。也可以将物理层的主要任务描述为确定与传输媒体的接口的一些特性，即：机械特性（接口所用接线器的一些物理属性如形状尺寸），电气特性（接口电缆的各条线上出现的电压的范围），功能特性（某条线上出现的某一电平的电压的意义），过程特性（对于不同功能能的各种可能事件的出现顺序）。 拓展： 物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。现有的计算机网络中的硬件设备和传输媒体的种类非常繁多，而且通信手段也有许多不同的方式。物理层的作用正是尽可能地屏蔽掉这些传输媒体和通信手段的差异，使物理层上面的数据链路层感觉不到这些差异，这样就可以使数据链路层只考虑完成本层的协议和服务，而不必考虑网络的具体传输媒体和通信手段是什么。 ②，几种常用的信道复用技术 ③，几种常用的宽带接入技术，主要是ADSL和FTTx 用户到互联网的宽带接入方法有非对称数字用户线ADSL（用数字技术对现有的模拟电话线进行改造，而不需要重新布线。ASDL的快速版本是甚高速数字用户线VDSL。），光纤同轴混合网HFC（是在目前覆盖范围很广的有线电视网的基础上开发的一种居民宽带接入网）和FTTx（即光纤到······）。 三数据链路层（1），基本术语 链路（link）：一个结点到相邻结点的一段物理链路 数据链路（data link）：把实现控制数据运输的协议的硬件和软件加到链路上就构成了数据链路 循环冗余检验CRC（Cyclic Redundancy Check）：为了保证数据传输的可靠性，CRC是数据链路层广泛使用的一种检错技术 帧（frame）：一个数据链路层的传输单元，由一个数据链路层首部和其携带的封包所组成协议数据单元。 MTU（Maximum Transfer Uint ）：最大传送单元。帧的数据部分的的长度上限。 误码率BER（Bit Error Rate ）：在一段时间内，传输错误的比特占所传输比特总数的比率。 PPP（Point-to-Point Protocol ）：点对点协议。即用户计算机和ISP进行通信时所使用的数据链路层协议。以下是PPP帧的示意图: MAC地址（Media Access Control或者Medium Access Control）：意译为媒体访问控制，或称为物理地址、硬件地址，用来定义网络设备的位置。 在OSI模型中，第三层网络层负责 IP地址，第二层数据链路层则负责 MAC地址。 因此一个主机会有一个MAC地址，而每个网络位置会有一个专属于它的IP地址 。 地址是识别某个系统的重要标识符，“名字指出我们所要寻找的资源，地址指出资源所在的地方，路由告诉我们如何到达该处” 网桥（bridge）：一种用于数据链路层实现中继，连接两个或多个局域网的网络互连设备。 交换机（switch ）：广义的来说，交换机指的是一种通信系统中完成信息交换的设备。这里工作在数据链路层的交换机指的是交换式集线器，其实质是一个多接口的网桥（2），重要知识点总结1，链路是从一个结点到相邻节点的一段物理链路，数据链路则在链路的基础上增加了一些必要的硬件（如网络适配器）和软件（如协议的实现） 2，数据链路层使用的主要是点对点信道和广播信道两种。 3，数据链路层传输的协议数据单元是帧。数据链路层的三个基本问题是：封装成帧，透明传输和差错检测 4，循环冗余检验CRC是一种检错方法，而帧检验序列FCS是添加在数据后面的冗余码 5，点对点协议PPP是数据链路层使用最多的一种协议，它的特点是：简单，只检测差错而不去纠正差错，不使用序号，也不进行流量控制，可同时支持多种网络层协议 6，PPPoE是为宽带上网的主机使用的链路层协议 7，局域网的优点是：具有广播功能，从一个站点可方便地访问全网；便于系统的扩展和逐渐演变；提高了系统的可靠性，可用性和生存性。 8，共向媒体通信资源的方法有二：一是静态划分信道(各种复用技术)，而是动态媒体接入控制，又称为多点接入（随即接入或受控接入） 9，计算机与外接局域网通信需要通过通信适配器（或网络适配器），它又称为网络接口卡或网卡。计算器的硬件地址就在适配器的ROM中。 10，以太网采用的无连接的工作方式，对发送的数据帧不进行编号，也不要求对方发回确认。目的站收到有差错帧就把它丢掉，其他什么也不做 11，以太网采用的协议是具有冲突检测的载波监听多点接入CSMA/CD。协议的特点是：发送前先监听，边发送边监听，一旦发现总线上出现了碰撞，就立即停止发送。然后按照退避算法等待一段随机时间后再次发送。 因此，每一个站点在自己发送数据之后的一小段时间内，存在这遭遇碰撞的可能性。以太网上的各站点平等的争用以太网信道 12，以太网的适配器具有过滤功能，它只接收单播帧，广播帧和多播帧。 13，使用集线器可以在物理层扩展以太网（扩展后的以太网仍然是一个网络） （3），最重要的知识点① 数据链路层的点对点信道和广播信道的特点，以及这两种信道所使用的协议（PPP协议以及CSMA/CD协议）的特点② 数据链路层的三个基本问题：封装成帧，透明传输，差错检测③ 以太网的MAC层硬件地址④ 适配器，转发器，集线器，网桥，以太网交换机的作用以及适用场合四网络层（1），基本术语虚电路（Virtual Circuit）：在两个终端设备的逻辑或物理端口之间，通过建立的双向的透明传输通道。虚电路表示这只是一条逻辑上的连接，分组都沿着这条逻辑连接按照存储转发方式传送，而并不是真正建立了一条物理连接。IP（Internet Protocol ）：网际协议 IP 是 TCP/IP体系中两个最主要的协议之一，是TCP/IP体系结构网际层的核心。配套的有ARP，RARP，ICMP，IGMP。 ARP（Address Resolution Protocol）：地址解析协议ICMP（Internet Control Message Protocol ）：网际控制报文协议 （ICMP 允许主机或路由器报告差错情况和提供有关异常情况的报告。）子网掩码（subnet mask ）：它是一种用来指明一个IP地址的哪些位标识的是主机所在的子网以及哪些位标识的是主机的位掩码。子网掩码不能单独存在，它必须结合IP地址一起使用。 CIDR（ Classless Inter-Domain Routing ）：无分类域间路由选择 （特点是消除了传统的 A 类、B 类和 C 类地址以及划分子网的概念，并使用各种长度的“网络前缀”(network-prefix)来代替分类地址中的网络号和子网号）默认路由（default route）：当在路由表中查不到能到达目的地址的路由时，路由器选择的路由。默认路由还可以减小路由表所占用的空间和搜索路由表所用的时间。路由选择算法（Virtual Circuit）：路由选择协议的核心部分。因特网采用自适应的，分层次的路由选择协议。（2），重要知识点总结1，TCP/IP协议中的网络层向上只提供简单灵活的，无连接的，尽最大努力交付的数据报服务。网络层不提供服务质量的承诺，不保证分组交付的时限所传送的分组可能出错，丢失，重复和失序。进程之间通信的可靠性由运输层负责 2，在互联网的交付有两种，一是在本网络直接交付不用经过路由器，另一种是和其他网络的间接交付，至少经过一个路由器，但最后一次一定是直接交付 3，分类的IP地址由网络号字段（指明网络）和主机号字段（指明主机）组成。网络号字段最前面的类别指明IP地址的类别。IP地址市一中分等级的地址结构。IP地址管理机构分配IP地址时只分配网络号，主机号由得到该网络号的单位自行分配。路由器根据目的主机所连接的网络号来转发分组。一个路由器至少连接到两个网络，所以一个路由器至少应当有两个不同的IP地址 4，IP数据报分为首部和数据两部分。首部的前一部分是固定长度，共20字节，是所有IP数据包必须具有的（源地址，目的地址，总长度等重要地段都固定在首部）。一些长度可变的可选字段固定在首部的后面。IP首部中的生存时间给出了IP数据报在互联网中所能经过的最大路由器数。可防止IP数据报在互联网中无限制的兜圈子。 5，地址解析协议ARP把IP地址解析为硬件地址。ARP的高速缓存可以大大减少网络上的通信量。因为这样可以使主机下次再与同样地址的主机通信时，可以直接从高速缓存中找到所需要的硬件地址而不需要再去广播方式发送ARP请求分组 6，无分类域间路由选择CIDR是解决目前IP地址紧缺的一个好办法。CIDR记法把IP地址后面加上斜线“/”，然后写上前缀所所占的位数。前缀（或网络前缀用来指明网络），前缀后面的部分是后缀，用来指明主机。CIDR把前缀都相同的连续的IP地址组成一个“CIDR地址块”，IP地址分配都以CIDR地址块为单位。 7， 网际控制报文协议是IP层的协议.ICMP报文作为IP数据报的数据，加上首部后组成IP数据报发送出去。使用ICMP数据报并不是为了实现可靠传输。ICMP允许主机或路由器报告差错情况和提供有关异常情况的报告。ICMP报文的种类有两种 ICMP差错报告报文和ICMP询问报文。 8，要解决IP地址耗尽的问题，最根本的办法是采用具有更大地址弓箭的新版本IP协议-IPv6。IPv6所带来的变化有①更大的地址空间（采用128位地址）②灵活的首部格式③改进的选项④支持即插即用⑤支持资源的预分配⑥IPv6的首部改为8字节对齐。另外IP数据报的目的地址可以是以下三种基本类型地址之一：单播，多播和任播 9，虚拟专用网络VPN利用公用的互联网作为本机构专用网之间的通信载体。VPN内使用互联网的专用地址。一个VPN至少要有一个路由器具有合法的全球IP地址，这样才能和本系统的另一个VPN通过互联网进行通信。所有通过互联网传送的数据都需要加密 10， MPLS的特点是：①支持面向连接的服务质量②支持流量工程，平衡网络负载③有效的支持虚拟专用网VPN。MPLS在入口节点给每一个IP数据报打上固定长度的“标记”，然后根据标记在第二层（链路层）用硬件进行转发（在标记交换路由器中进行标记交换），因而转发速率大大加快。 （3），最重要知识点① 虚拟互联网络的概念② IP地址和物理地址的关系③ 传统的分类的IP地址（包括子网掩码）和误分类域间路由选择CIDR④ 路由选择协议的工作原理五运输层（1），基本术语进程（process）：指计算机中正在运行的程序实体应用进程互相通信：一台主机的进程和另一台主机中的一个进程交换数据的过程（另外注意通信真正的端点不是主机而是主机中的进程，也就是说端到端的通信是应用进程之间的通信）传输层的复用与分用：复用指发送方不同的进程都可以通过统一个运输层协议传送数据。分用指接收方的运输层在剥去报文的首部后能把这些数据正确的交付到目的应用进程。 TCP（Transmission Control Protocol）：传输控制协议UDP（User Datagram Protocol）：用户数据报协议端口（port）（link）：端口的目的是为了确认对方机器是那个进程在于自己进行交互，比如MSN和QQ的端口不同，如果没有端口就可能出现QQ进程和MSN交互错误。端口又称协议端口号。 停止等待协议（link）：指发送方每发送完一个分组就停止发送，等待对方确认，在收到确认之后在发送下一个分组。流量控制（link）：就是让发送方的发送速率不要太快，既要让接收方来得及接收，也不要使网络发生拥塞。拥塞控制（link）：防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。（2），重要知识点总结1，运输层提供应用进程之间的逻辑通信，也就是说，运输层之间的通信并不是真正在两个运输层之间直接传输数据。运输层向应用层屏蔽了下面网络的细节（如网络拓补，所采用的路由选择协议等），它使应用进程之间看起来好像两个运输层实体之间有一条端到端的逻辑通信信道。 2，网络层为主机提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信。 3，运输层的两个重要协议是用户数据报协议UDP和传输控制协议TCP。按照OSI的术语，两个对等运输实体在通信时传送的数据单位叫做运输协议数据单元TPDU（Transport Protocol Data Unit）。但在TCP/IP体系中，则根据所使用的协议是TCP或UDP，分别称之为TCP报文段或UDP用户数据报。 4，UDP在传送数据之前不需要先建立连接，远地主机在收到UDP报文后，不需要给出任何确认。虽然UDP不提供可靠交付，但在某些情况下UDP确是一种最有效的工作方式。 TCP提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP不提供广播或多播服务。由于TCP要提供可靠的，面向连接的传输服务，这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。 5，硬件端口是不同硬件设备进行交互的接口，而软件端口是应用层各种协议进程与运输实体进行层间交互的一种地址。UDP和TCP的首部格式中都有源端口和目的端口这两个重要字段。当运输层收到IP层交上来的运输层报文时，就能够 根据其首部中的目的端口号把数据交付应用层的目的应用层。（两个进程之间进行通信不光要知道对方IP地址而且要知道对方的端口号(为了找到对方计算机中的应用进程)） 6，运输层用一个16位端口号标志一个端口。端口号只有本地意义，它只是为了标志计算机应用层中的各个进程在和运输层交互时的层间接口。在互联网的不同计算机中，相同的端口号是没有关联的。协议端口号简称端口。虽然通信的终点是应用进程，但只要把所发送的报文交到目的主机的某个合适端口，剩下的工作（最后交付目的进程）就由TCP和UDP来完成。 7，运输层的端口号分为服务器端使用的端口号（01023指派给熟知端口，102449151是登记端口号）和客户端暂时使用的端口号（49152~65535） 8，UDP的主要特点是①无连接②尽最大努力交付③面向报文④无拥塞控制⑤支持一对一，一对多，多对一和多对多的交互通信⑥首部开销小（只有四个字段：源端口，目的端口，长度和检验和） 9，TCP的主要特点是①面向连接②每一条TCP连接只能是一对一的③提供可靠交付④提供全双工通信⑤面向字节流 10，TCP用主机的IP地址加上主机上的端口号作为TCP连接的端点。这样的端点就叫做套接字（socket）或插口。套接字用（IP地址：端口号）来表示。每一条TCP连接唯一被通信两端的两个端点所确定。 11，停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 12，为了提高传输效率，发送方可以不使用低效率的停止等待协议，而是采用流水线传输。流水线传输就是发送方可连续发送多个分组，不必每发完一个分组就停下来等待对方确认。这样可使信道上一直有数据不间断的在传送。这种传输方式可以明显提高信道利用率。 13，停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求ARQ。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。连续ARQ协议可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。 14，TCP报文段的前20个字节是固定的，后面有4n字节是根据需要增加的选项。因此，TCP首部的最小长度是20字节。 15，TCP使用滑动窗口机制。发送窗口里面的序号表示允许发送的序号。发送窗口后沿的后面部分表示已发送且已收到确认，而发送窗口前沿的前面部分表示不晕与发送。发送窗口后沿的变化情况有两种可能，即不动（没有收到新的确认）和前移（收到了新的确认）。发送窗口的前沿通常是不断向前移动的。一般来说，我们总是希望数据传输更快一些。但如果发送方把数据发送的过快，接收方就可能来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。 16，在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 17，为了进行拥塞控制，TCP发送方要维持一个拥塞窗口cwnd的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 18，TCP的拥塞控制采用了四种算法，即慢开始，拥塞避免，快重传和快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理AQM），以减少网络拥塞的发生。 19，运输连接的三个阶段，即：连接建立，数据传送和连接释放。 20，主动发起TCP连接建立的应用进程叫做客户，而被动等待连接建立的应用进程叫做服务器。TCP连接采用三报文握手机制。服务器要确认用户的连接请求，然后客户要对服务器的确认进行确认。 21，TCP的连接释放采用四报文握手机制。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送时，则发送连接释放通知，对方确认后就完全关闭了TCP连接 （3），最重要的知识点① 端口和套接字的意义② 无连接UDP的特点③ 面向连接TCP的特点④ 在不可靠的网络上实现可靠传输的工作原理，停止等待协议和ARQ协议① TCP的滑动窗口，流量控制，拥塞控制和连接管理六应用层（1），基本术语 域名系统（DNS）：DNS（Domain Name System，域名系统），万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。 通过域名，最终得到该域名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。在RFC文档中RFC 2181对DNS有规范说明，RFC 2136对DNS的动态更新进行说明，RFC 2308对DNS查询的反向缓存进行说明。 文件传输协议（FTP）：FTP 是File TransferProtocol（文件传输协议）的英文简称，而中文简称为“文传协议”。用于Internet上的控制文件的双向传输。同时，它也是一个应用程序（Application）。 基于不同的操作系统有不同的FTP应用程序，而所有这些应用程序都遵守同一种协议以传输文件。在FTP的使用当中，用户经常遇到两个概念：&quot;下载&quot;（Download）和&quot;上传&quot;（Upload）。 &quot;下载&quot;文件就是从远程主机拷贝文件至自己的计算机上；&quot;上传&quot;文件就是将文件从自己的计算机中拷贝至远程主机上。用Internet语言来说，用户可通过客户机程序向（从）远程主机上传（下载）文件。 简单文件传输协议（TFTP）：TFTP（Trivial File Transfer Protocol,简单文件传输协议）是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供不复杂、开销不大的文件传输服务。端口号为69。 远程终端协议（TELENET）：Telnet协议是TCP/IP协议族中的一员，是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的能力。 在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。 可以在本地就能控制服务器。要开始一个telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。 万维网（WWW）：WWW是环球信息网的缩写，（亦作“Web”、“WWW”、“&apos;W3&apos;”，英文全称为“World Wide Web”），中文名字为“万维网”，&quot;环球网&quot;等，常简称为Web。分为Web客户端和Web服务器程序。 WWW可以让Web客户端（常用浏览器）访问浏览Web服务器上的页面。是一个由许多互相链接的超文本组成的系统，通过互联网访问。在这个系统中，每个有用的事物，称为一样“资源”；并且由一个全局“统一资源标识符”（URI）标识；这些资源通过超文本传输协议（Hypertext Transfer Protocol）传送给用户，而后者通过点击链接来获得资源。 万维网联盟（英语：World Wide Web Consortium，简称W3C），又称W3C理事会。1994年10月在麻省理工学院（MIT）计算机科学实验室成立。万维网联盟的创建者是万维网的发明者蒂姆·伯纳斯-李。 万维网并不等同互联网，万维网只是互联网所能提供的服务其中之一，是靠着互联网运行的一项服务。 万维网的大致工作工程： 统一资源定位符（URL）：统一资源定位符是对可以从互联网上得到的资源的位置和访问方法的一种简洁的表示，是互联网上标准资源的地址。互联网上的每个文件都有一个唯一的URL，它包含的信息指出文件的位置以及浏览器应该怎么处理它。 超文本传输协议（HTTP）：超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。 设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。1960年美国人Ted Nelson构思了一种通过计算机处理文本信息的方法，并称之为超文本（hypertext）,这成为了HTTP超文本传输协议标准架构的发展根基。 代理服务器（Proxy Server）：代理服务器（Proxy Server）是一种网络实体，它又称为万维网高速缓存。 代理服务器把最近的一些请求和响应暂存在本地磁盘中。当新请求到达时，若代理服务器发现这个请求与暂时存放的的请求相同，就返回暂存的响应，而不需要按URL的地址再次去互联网访问该资源。 代理服务器可在客户端或服务器工作，也可以在中间系统工作。 http请求头：http请求头，HTTP客户程序（例如浏览器），向服务器发送请求的时候必须指明请求类型（一般是GET或者POST）。如有必要，客户程序还可以选择发送其他的请求头。 - Accept：浏览器可接受的MIME类型。 - Accept-Charset：浏览器可接受的字符集。 - Accept-Encoding：浏览器能够进行解码的数据编码方式，比如gzip。Servlet能够向支持gzip的浏览器返回经gzip编码的HTML页面。许多情形下这可以减少5到10倍的下载时间。 - Accept-Language：浏览器所希望的语言种类，当服务器能够提供一种以上的语言版本时要用到。 - Authorization：授权信息，通常出现在对服务器发送的WWW-Authenticate头的应答中。 - Connection：表示是否需要持久连接。如果Servlet看到这里的值为“Keep-Alive”，或者看到请求使用的是HTTP 1.1（HTTP 1.1默认进行持久连接），它就可以利用持久连接的优点，当页面包含多个元素时（例如Applet，图片），显著地减少下载所需要的时间。要实现这一点，Servlet需要在应答中发送一个Content-Length头，最简单的实现方法是：先把内容写入ByteArrayOutputStream，然后在正式写出内容之前计算它的大小。 - Content-Length：表示请求消息正文的长度。 - Cookie：这是最重要的请求头信息之一 - From：请求发送者的email地址，由一些特殊的Web客户程序使用，浏览器不会用到它。 - Host：初始URL中的主机和端口。 - If-Modified-Since：只有当所请求的内容在指定的日期之后又经过修改才返回它，否则返回304“Not Modified”应答。 - Pragma：指定“no-cache”值表示服务器必须返回一个刷新后的文档，即使它是代理服务器而且已经有了页面的本地拷贝。 - Referer：包含一个URL，用户从该URL代表的页面出发访问当前请求的页面。 - User-Agent：浏览器类型，如果Servlet返回的内容与浏览器类型有关则该值非常有用。简单邮件传输协议(SMTP)：SMTP（Simple Mail Transfer Protocol）即简单邮件传输协议,它是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。 SMTP协议属于TCP/IP协议簇，它帮助每台计算机在发送或中转信件时找到下一个目的地。 通过SMTP协议所指定的服务器,就可以把E-mail寄到收信人的服务器上了，整个过程只要几分钟。SMTP服务器则是遵循SMTP协议的发送邮件服务器，用来发送或中转发出的电子邮件。搜索引擎：搜索引擎（Search Engine）是指根据一定的策略、运用特定的计算机程序从互联网上搜集信息，在对信息进行组织和处理后，为用户提供检索服务，将用户检索相关的信息展示给用户的系统。 搜索引擎包括全文索引、目录索引、元搜索引擎、垂直搜索引擎、集合式搜索引擎、门户搜索引擎与免费链接列表等。全文索引： 全文索引技术是目前搜索引擎的关键技术。 试想在1M大小的文件中搜索一个词，可能需要几秒，在100M的文件中可能需要几十秒，如果在更大的文件中搜索那么就需要更大的系统开销，这样的开销是不现实的。 所以在这样的矛盾下出现了全文索引技术，有时候有人叫倒排文档技术。目录索引：目录索引（ search index/directory)，顾名思义就是将网站分门别类地存放在相应的目录中，因此用户在查询信息时，可选择关键词搜索，也可按分类目录逐层查找。垂直搜索引擎：垂直搜索引擎是针对某一个行业的专业搜索引擎，是搜索引擎的细分和延伸，是对网页库中的某类专门的信息进行一次整合，定向分字段抽取出需要的数据进行处理后再以某种形式返回给用户。 垂直搜索是相对通用搜索引擎的信息量大、查询不准确、深度不够等提出来的新的搜索引擎服务模式，通过针对某一特定领域、某一特定人群或某一特定需求提供的有一定价值的信息和相关服务。 其特点就是“专、精、深”，且具有行业色彩，相比较通用搜索引擎的海量信息无序化，垂直搜索引擎则显得更加专注、具体和深入。（2），重要知识点总结1，文件传输协议（FTP）使用TCP可靠的运输服务。FTP使用客户服务器方式。一个FTP服务器进程可以同时为多个用户提供服务。在进进行文件传输时，FTP的客户和服务器之间要先建立两个并行的TCP连接:控制连接和数据连接。实际用于传输文件的是数据连接。 2，万维网客户程序与服务器之间进行交互使用的协议时超文本传输协议HTTP。HTTP使用TCP连接进行可靠传输。但HTTP本身是无连接、无状态的。HTTP/1.1协议使用了持续连接（分为非流水线方式和流水线方式） 3，电子邮件把邮件发送到收件人使用的邮件服务器，并放在其中的收件人邮箱中，收件人可随时上网到自己使用的邮件服务器读取，相当于电子邮箱。 4，一个电子邮件系统有三个重要组成构件：用户代理、邮件服务器、邮件协议（包括邮件发送协议，如SMTP，和邮件读取协议，如POP3和IMAP）。用户代理和邮件服务器都要运行这些协议。 （3），最重要知识点总结① 域名系统-从域名解析出IP地址② 访问一个网站大致的过程③ 系统调用和应用编程接口概念","categories":[],"tags":[{"name":"Http","slug":"Http","permalink":"http://zhoumoon.github.io/tags/Http/"}]},{"title":"一千行MySQL命令","slug":"一千行MySQL命令","date":"2018-02-03T23:11:02.000Z","updated":"2021-02-08T08:11:26.289Z","comments":false,"path":"2018/02/04/一千行MySQL命令/","link":"","permalink":"http://zhoumoon.github.io/2018/02/04/一千行MySQL命令/","excerpt":"","text":"非常不错的总结，强烈建议保存下来，需要的时候看一看。 基本操作 数据库操作 表的操作 数据操作 字符集编码 数据类型(列类型) 列属性(列约束) 建表规范 SELECT UNION 子查询 连接查询(join) TRUNCATE 备份与还原 视图 事务(transaction) 锁表 触发器 SQL编程 存储过程 用户和权限管理 表维护 杂项 基本操作123456789/* Windows服务 */-- 启动MySQL net start mysql-- 创建Windows服务 sc create mysql binPath= mysqld_bin_path(注意：等号与值之间有空格)/* 连接与断开服务器 */mysql -h 地址 -P 端口 -u 用户名 -p 密码SHOW PROCESSLIST -- 显示哪些线程正在运行SHOW VARIABLES -- 显示系统变量信息 数据库操作12345678910111213141516171819/* 数据库操作 */ -------------------- 查看当前数据库 SELECT DATABASE();-- 显示当前时间、用户名、数据库版本 SELECT now(), user(), version();-- 创建库 CREATE DATABASE[ IF NOT EXISTS] 数据库名 数据库选项 数据库选项： CHARACTER SET charset_name COLLATE collation_name-- 查看已有库 SHOW DATABASES[ LIKE &apos;PATTERN&apos;]-- 查看当前库信息 SHOW CREATE DATABASE 数据库名-- 修改库的选项信息 ALTER DATABASE 库名 选项信息-- 删除库 DROP DATABASE[ IF EXISTS] 数据库名 同时删除该数据库相关的目录及其目录内容 表的操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576-- 创建表 CREATE [TEMPORARY] TABLE[ IF NOT EXISTS] [库名.]表名 ( 表的结构定义 )[ 表选项] 每个字段必须有数据类型 最后一个字段后不能有逗号 TEMPORARY 临时表，会话结束时表自动消失 对于字段的定义： 字段名 数据类型 [NOT NULL | NULL] [DEFAULT default_value] [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT &apos;string&apos;]-- 表选项 -- 字符集 CHARSET = charset_name 如果表没有设定，则使用数据库字符集 -- 存储引擎 ENGINE = engine_name 表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性操作等不同 常见的引擎：InnoDB MyISAM Memory/Heap BDB Merge Example CSV MaxDB Archive 不同的引擎在保存表的结构和数据时采用不同的方式 MyISAM表文件含义：.frm表定义，.MYD表数据，.MYI表索引 InnoDB表文件含义：.frm表定义，表空间数据和日志文件 SHOW ENGINES -- 显示存储引擎的状态信息 SHOW ENGINE 引擎名 &#123;LOGS|STATUS&#125; -- 显示存储引擎的日志或状态信息 -- 自增起始数 AUTO_INCREMENT = 行数 -- 数据文件目录 DATA DIRECTORY = &apos;目录&apos; -- 索引文件目录 INDEX DIRECTORY = &apos;目录&apos; -- 表注释 COMMENT = &apos;string&apos; -- 分区选项 PARTITION BY ... (详细见手册)-- 查看所有表 SHOW TABLES[ LIKE &apos;pattern&apos;] SHOW TABLES FROM 库名-- 查看表机构 SHOW CREATE TABLE 表名 （信息更详细） DESC 表名 / DESCRIBE 表名 / EXPLAIN 表名 / SHOW COLUMNS FROM 表名 [LIKE &apos;PATTERN&apos;] SHOW TABLE STATUS [FROM db_name] [LIKE &apos;pattern&apos;]-- 修改表 -- 修改表本身的选项 ALTER TABLE 表名 表的选项 eg: ALTER TABLE 表名 ENGINE=MYISAM; -- 对表进行重命名 RENAME TABLE 原表名 TO 新表名 RENAME TABLE 原表名 TO 库名.表名 （可将表移动到另一个数据库） -- RENAME可以交换两个表名 -- 修改表的字段机构（13.1.2. ALTER TABLE语法） ALTER TABLE 表名 操作名 -- 操作名 ADD[ COLUMN] 字段定义 -- 增加字段 AFTER 字段名 -- 表示增加在该字段名后面 FIRST -- 表示增加在第一个 ADD PRIMARY KEY(字段名) -- 创建主键 ADD UNIQUE [索引名] (字段名)-- 创建唯一索引 ADD INDEX [索引名] (字段名) -- 创建普通索引 DROP[ COLUMN] 字段名 -- 删除字段 MODIFY[ COLUMN] 字段名 字段属性 -- 支持对字段属性进行修改，不能修改字段名(所有原有属性也需写上) CHANGE[ COLUMN] 原字段名 新字段名 字段属性 -- 支持对字段名修改 DROP PRIMARY KEY -- 删除主键(删除主键前需删除其AUTO_INCREMENT属性) DROP INDEX 索引名 -- 删除索引 DROP FOREIGN KEY 外键 -- 删除外键-- 删除表 DROP TABLE[ IF EXISTS] 表名 ...-- 清空表数据 TRUNCATE [TABLE] 表名-- 复制表结构 CREATE TABLE 表名 LIKE 要复制的表名-- 复制表结构和数据 CREATE TABLE 表名 [AS] SELECT * FROM 要复制的表名-- 检查表是否有错误 CHECK TABLE tbl_name [, tbl_name] ... [option] ...-- 优化表 OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...-- 修复表 REPAIR [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... [QUICK] [EXTENDED] [USE_FRM]-- 分析表 ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... 数据操作1234567891011121314151617/* 数据操作 */ -------------------- 增 INSERT [INTO] 表名 [(字段列表)] VALUES (值列表)[, (值列表), ...] -- 如果要插入的值列表包含所有字段并且顺序一致，则可以省略字段列表。 -- 可同时插入多条数据记录！ REPLACE 与 INSERT 完全一样，可互换。 INSERT [INTO] 表名 SET 字段名=值[, 字段名=值, ...]-- 查 SELECT 字段列表 FROM 表名[ 其他子句] -- 可来自多个表的多个字段 -- 其他子句可以不使用 -- 字段列表可以用*代替，表示所有字段-- 删 DELETE FROM 表名[ 删除条件子句] 没有条件子句，则会删除全部-- 改 UPDATE 表名 SET 字段名=新值[, 字段名=新值] [更新条件] 字符集编码123456789101112131415161718/* 字符集编码 */ -------------------- MySQL、数据库、表、字段均可设置编码-- 数据编码与客户端编码不需一致SHOW VARIABLES LIKE &apos;character_set_%&apos; -- 查看所有字符集编码项 character_set_client 客户端向服务器发送数据时使用的编码 character_set_results 服务器端将结果返回给客户端所使用的编码 character_set_connection 连接层编码SET 变量名 = 变量值 SET character_set_client = gbk; SET character_set_results = gbk; SET character_set_connection = gbk;SET NAMES GBK; -- 相当于完成以上三个设置-- 校对集 校对集用以排序 SHOW CHARACTER SET [LIKE &apos;pattern&apos;]/SHOW CHARSET [LIKE &apos;pattern&apos;] 查看所有字符集 SHOW COLLATION [LIKE &apos;pattern&apos;] 查看所有校对集 CHARSET 字符集编码 设置字符集编码 COLLATE 校对集编码 设置校对集编码 数据类型(列类型)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697/* 数据类型（列类型） */ ------------------1. 数值类型-- a. 整型 ---------- 类型 字节 范围（有符号位） tinyint 1字节 -128 ~ 127 无符号位：0 ~ 255 smallint 2字节 -32768 ~ 32767 mediumint 3字节 -8388608 ~ 8388607 int 4字节 bigint 8字节 int(M) M表示总位数 - 默认存在符号位，unsigned 属性修改 - 显示宽度，如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改 例：int(5) 插入一个数&apos;123&apos;，补填后为&apos;00123&apos; - 在满足要求的情况下，越小越好。 - 1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型。-- b. 浮点型 ---------- 类型 字节 范围 float(单精度) 4字节 double(双精度) 8字节 浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性。 不同于整型，前后均会补填0. 定义浮点型时，需指定总位数和小数位数。 float(M, D) double(M, D) M表示总位数，D表示小数位数。 M和D的大小会决定浮点数的范围。不同于整型的固定范围。 M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）。 支持科学计数法表示。 浮点数表示近似值。-- c. 定点数 ---------- decimal -- 可变长度 decimal(M, D) M也表示总位数，D表示小数位数。 保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入。 将浮点数转换为字符串来保存，每9位数字保存为4个字节。2. 字符串类型-- a. char, varchar ---------- char 定长字符串，速度快，但浪费空间 varchar 变长字符串，速度慢，但节省空间 M表示能存储的最大长度，此长度是字符数，非字节数。 不同的编码，所占用的空间不同。 char,最多255个字符，与编码无关。 varchar,最多65535字符，与编码有关。 一条有效记录最大不能超过65535个字节。 utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符 varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。 varchar 的最大有效长度由最大行大小和使用的字符集确定。 最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是64432-1-2=65532字节。 例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？ 答：(65535-1-2-4-30*3)/3-- b. blob, text ---------- blob 二进制字符串（字节字符串） tinyblob, blob, mediumblob, longblob text 非二进制字符串（字符字符串） tinytext, text, mediumtext, longtext text 在定义时，不需要定义长度，也不会计算总长度。 text 类型在定义时，不可给default值-- c. binary, varbinary ---------- 类似于char和varchar，用于保存二进制字符串，也就是保存字节字符串而非字符字符串。 char, varchar, text 对应 binary, varbinary, blob.3. 日期时间类型 一般用整型保存时间戳，因为PHP可以很方便的将时间戳进行格式化。 datetime 8字节 日期及时间 1000-01-01 00:00:00 到 9999-12-31 23:59:59 date 3字节 日期 1000-01-01 到 9999-12-31 timestamp 4字节 时间戳 19700101000000 到 2038-01-19 03:14:07 time 3字节 时间 -838:59:59 到 838:59:59 year 1字节 年份 1901 - 2155datetime YYYY-MM-DD hh:mm:sstimestamp YY-MM-DD hh:mm:ss YYYYMMDDhhmmss YYMMDDhhmmss YYYYMMDDhhmmss YYMMDDhhmmssdate YYYY-MM-DD YY-MM-DD YYYYMMDD YYMMDD YYYYMMDD YYMMDDtime hh:mm:ss hhmmss hhmmssyear YYYY YY YYYY YY4. 枚举和集合-- 枚举(enum) ----------enum(val1, val2, val3...) 在已知的值中进行单选。最大数量为65535. 枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。 表现为字符串类型，存储却是整型。 NULL值的索引是NULL。 空字符串错误值的索引值是0。-- 集合（set） ----------set(val1, val2, val3...) create table tab ( gender set(&apos;男&apos;, &apos;女&apos;, &apos;无&apos;) ); insert into tab values (&apos;男, 女&apos;); 最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式。 当创建表时，SET成员值的尾部空格将自动被删除。 列属性(列约束)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/* 列属性（列约束） */ ------------------1. PRIMARY 主键 - 能唯一标识记录的字段，可以作为主键。 - 一个表只能有一个主键。 - 主键具有唯一性。 - 声明字段时，用 primary key 标识。 也可以在字段列表之后声明 例：create table tab ( id int, stu varchar(10), primary key (id)); - 主键字段的值不能为null。 - 主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。 例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age));2. UNIQUE 唯一索引（唯一约束） 使得某字段的值也不能重复。3. NULL 约束 null不是数据类型，是列的一个属性。 表示当前列是否可以为null，表示什么都没有。 null, 允许为空。默认。 not null, 不允许为空。 insert into tab values (null, &apos;val&apos;); -- 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null4. DEFAULT 默认值属性 当前字段的默认值。 insert into tab values (default, &apos;val&apos;); -- 此时表示强制使用默认值。 create table tab ( add_time timestamp default current_timestamp ); -- 表示将当前时间的时间戳设为默认值。 current_date, current_time5. AUTO_INCREMENT 自动增长约束 自动增长必须为索引（主键或unique） 只能存在一个字段为自动增长。 默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x;6. COMMENT 注释 例：create table tab ( id int ) comment &apos;注释内容&apos;;7. FOREIGN KEY 外键约束 用于限制主表与从表数据完整性。 alter table t1 add constraint `t1_t2_fk` foreign key (t1_id) references t2(id); -- 将表t1的t1_id外键关联到表t2的id字段。 -- 每个外键都有一个名字，可以通过 constraint 指定 存在外键的表，称之为从表（子表），外键指向的表，称之为主表（父表）。 作用：保持数据一致性，完整性，主要目的是控制存储在外键表（从表）中的数据。 MySQL中，可以对InnoDB引擎使用外键约束： 语法： foreign key (外键字段） references 主表名 (关联字段) [主表记录删除时的动作] [主表记录更新时的动作] 此时需要检测一个从表的外键需要约束为主表的已存在的值。外键在没有关联的情况下，可以设置为null.前提是该外键列，没有not null。 可以不指定主表记录更改或更新时的动作，那么此时主表的操作被拒绝。 如果指定了 on update 或 on delete：在删除或更新时，有如下几个操作可以选择： 1. cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值更新）。主表记录被删除，从表相关记录也被删除。 2. set null，设置为null。主表数据被更新（主键值更新），从表的外键被设置为null。主表记录被删除，从表相关记录外键被设置成null。但注意，要求该外键列，没有not null属性约束。 3. restrict，拒绝父表删除和更新。 注意，外键只被InnoDB存储引擎所支持。其他引擎是不支持的。 建表规范1234567891011121314/* 建表规范 */ ------------------ -- Normal Format, NF - 每个表保存一个实体信息 - 每个具有一个ID字段作为主键 - ID主键 + 原子表 -- 1NF, 第一范式 字段不能再分，就满足第一范式。 -- 2NF, 第二范式 满足第一范式的前提下，不能出现部分依赖。 消除复合主键就可以避免部分依赖。增加单列关键字。 -- 3NF, 第三范式 满足第二范式的前提下，不能出现传递依赖。 某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。 将一个实体信息的数据放在一个表内实现。 SELECT123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/* SELECT */ ------------------SELECT [ALL|DISTINCT] select_expr FROM -&gt; WHERE -&gt; GROUP BY [合计函数] -&gt; HAVING -&gt; ORDER BY -&gt; LIMITa. select_expr -- 可以用 * 表示所有字段。 select * from tb; -- 可以使用表达式（计算公式、函数调用、字段也是个表达式） select stu, 29+25, now() from tb; -- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。 - 使用 as 关键字，也可省略 as. select stu+10 as add10 from tb;b. FROM 子句 用于标识查询来源。 -- 可以为表起别名。使用as关键字。 SELECT * FROM tb1 AS tt, tb2 AS bb; -- from子句后，可以同时出现多个表。 -- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。 SELECT * FROM tb1, tb2; -- 向优化符提示如何选择索引 USE INDEX、IGNORE INDEX、FORCE INDEX SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 AND key3=3; SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 AND key3=3;c. WHERE 子句 -- 从from获得的数据源中进行筛选。 -- 整型1表示真，0表示假。 -- 表达式由运算符和运算数组成。 -- 运算数：变量（字段）、值、函数返回值 -- 运算符： =, &lt;=&gt;, &lt;&gt;, !=, &lt;=, &lt;, &gt;=, &gt;, !, &amp;&amp;, ||, in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor is/is not 加上ture/false/unknown，检验某个值的真假 &lt;=&gt;与&lt;&gt;功能相同，&lt;=&gt;可用于null比较d. GROUP BY 子句, 分组子句 GROUP BY 字段/别名 [排序方式] 分组后会进行排序。升序：ASC，降序：DESC 以下[合计函数]需配合 GROUP BY 使用： count 返回不同的非NULL值数目 count(*)、count(字段) sum 求和 max 求最大值 min 求最小值 avg 求平均值 group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。e. HAVING 子句，条件子句 与 where 功能、用法相同，执行时机不同。 where 在开始时执行检测数据，对原数据进行过滤。 having 对筛选出的结果再次进行过滤。 having 字段必须是查询出来的，where 字段必须是数据表存在的。 where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。 where 不可以使用合计函数。一般需用合计函数才会用 having SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。f. ORDER BY 子句，排序子句 order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]... 升序：ASC，降序：DESC 支持多个字段的排序。g. LIMIT 子句，限制结果数量子句 仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。 limit 起始位置, 获取条数 省略第一个参数，表示从索引0开始。limit 获取条数h. DISTINCT, ALL 选项 distinct 去除重复记录 默认为 all, 全部记录 UNION12345678/* UNION */ ------------------ 将多个select查询的结果组合成一个结果集合。 SELECT ... UNION [ALL|DISTINCT] SELECT ... 默认 DISTINCT 方式，即所有返回的行都是唯一的 建议，对每个SELECT查询加上小括号包裹。 ORDER BY 排序时，需加上 LIMIT 进行结合。 需要各select查询的字段数量一样。 每个select查询的字段列表(数量、类型)应一致，因为结果中的字段名以第一条select语句为准。 子查询1234567891011121314151617181920212223242526272829/* 子查询 */ ------------------ - 子查询需用括号包裹。-- from型 from后要求是一个表，必须给子查询结果取个别名。 - 简化每个查询内的条件。 - from型需将结果生成一个临时表格，可用以原表的锁定的释放。 - 子查询返回一个表，表型子查询。 select * from (select * from tb where id&gt;0) as subfrom where id&gt;1;-- where型 - 子查询返回一个值，标量子查询。 - 不需要给子查询取别名。 - where子查询内的表，不能直接用以更新。 select * from tb where money = (select max(money) from tb); -- 列子查询 如果子查询结果返回的是一列。 使用 in 或 not in 完成查询 exists 和 not exists 条件 如果子查询返回数据，则返回1或0。常用于判断条件。 select column1 from t1 where exists (select * from t2); -- 行子查询 查询条件是一个行。 select * from t1 where (id, gender) in (select id, gender from t2); 行构造符：(col1, col2, ...) 或 ROW(col1, col2, ...) 行构造符通常用于与对能返回两个或两个以上列的子查询进行比较。 -- 特殊运算符 != all() 相当于 not in = some() 相当于 in。any 是 some 的别名 != some() 不等同于 not in，不等于其中某一个。 all, some 可以配合其他运算符一起使用。 连接查询(join)123456789101112131415161718192021222324/* 连接查询(join) */ ------------------ 将多个表的字段进行连接，可以指定连接条件。-- 内连接(inner join) - 默认就是内连接，可省略inner。 - 只有数据存在时才能发送连接。即连接结果不能出现空行。 on 表示连接条件。其条件表达式与where类似。也可以省略条件（表示条件永远为真） 也可用where表示连接条件。 还有 using, 但需字段名相同。 using(字段名) -- 交叉连接 cross join 即，没有条件的内连接。 select * from tb1 cross join tb2;-- 外连接(outer join) - 如果数据不存在，也会出现在连接结果中。 -- 左外连接 left join 如果数据不存在，左表记录会出现，而右表为null填充 -- 右外连接 right join 如果数据不存在，右表记录会出现，而左表为null填充-- 自然连接(natural join) 自动判断连接条件完成连接。 相当于省略了using，会自动查找相同字段名。 natural join natural left join natural right joinselect info.id, info.name, info.stu_num, extra_info.hobby, extra_info.sex from info, extra_info where info.stu_num = extra_info.stu_id; TRUNCATE123456789/* TRUNCATE */ ------------------TRUNCATE [TABLE] tbl_name清空数据删除重建表区别：1，truncate 是删除表再创建，delete 是逐条删除2，truncate 重置auto_increment的值。而delete不会3，truncate 不知道删除了几条，而delete知道。4，当被用于带分区的表时，truncate 会保留分区 备份与还原123456789101112131415161718192021/* 备份与还原 */ ------------------备份，将数据的结构与表内数据保存起来。利用 mysqldump 指令完成。-- 导出mysqldump [options] db_name [tables]mysqldump [options] ---database DB1 [DB2 DB3...]mysqldump [options] --all--database1. 导出一张表 mysqldump -u用户名 -p密码 库名 表名 &gt; 文件名(D:/a.sql)2. 导出多张表 mysqldump -u用户名 -p密码 库名 表1 表2 表3 &gt; 文件名(D:/a.sql)3. 导出所有表 mysqldump -u用户名 -p密码 库名 &gt; 文件名(D:/a.sql)4. 导出一个库 mysqldump -u用户名 -p密码 --lock-all-tables --database 库名 &gt; 文件名(D:/a.sql)可以-w携带WHERE条件-- 导入1. 在登录mysql的情况下： source 备份文件2. 在不登录的情况下 mysql -u用户名 -p密码 库名 &lt; 备份文件 视图1234567891011121314151617181920212223242526272829什么是视图： 视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。 视图具有表结构文件，但不存在数据文件。 对其中所引用的基础表来说，视图的作用类似于筛选。定义视图的筛选可以来自当前或其它数据库的一个或多个表，或者其它视图。通过视图进行查询没有任何限制，通过它们进行数据修改时的限制也很少。 视图是存储在数据库中的查询的sql语句，它主要出于两种原因：安全原因，视图可以隐藏一些数据，如：社会保险基金表，可以用视图只显示姓名，地址，而不显示社会保险号和工资数等，另一原因是可使复杂的查询易于理解和使用。-- 创建视图CREATE [OR REPLACE] [ALGORITHM = &#123;UNDEFINED | MERGE | TEMPTABLE&#125;] VIEW view_name [(column_list)] AS select_statement - 视图名必须唯一，同时不能与表重名。 - 视图可以使用select语句查询到的列名，也可以自己指定相应的列名。 - 可以指定视图执行的算法，通过ALGORITHM指定。 - column_list如果存在，则数目必须等于SELECT语句检索的列数-- 查看结构 SHOW CREATE VIEW view_name-- 删除视图 - 删除视图后，数据依然存在。 - 可同时删除多个视图。 DROP VIEW [IF EXISTS] view_name ...-- 修改视图结构 - 一般不修改视图，因为不是所有的更新视图都会映射到表上。 ALTER VIEW view_name [(column_list)] AS select_statement-- 视图作用 1. 简化业务逻辑 2. 对客户端隐藏真实的表结构-- 视图算法(ALGORITHM) MERGE 合并 将视图的查询语句，与外部查询需要先合并再执行！ TEMPTABLE 临时表 将视图执行完毕后，形成临时表，再做外层查询！ UNDEFINED 未定义(默认)，指的是MySQL自主去选择相应的算法。 事务(transaction)123456789101112131415161718192021222324252627282930313233343536373839404142434445事务是指逻辑上的一组操作，组成这组操作的各个单元，要不全成功要不全失败。 - 支持连续SQL的集体成功或集体撤销。 - 事务是数据库在数据晚自习方面的一个功能。 - 需要利用 InnoDB 或 BDB 存储引擎，对自动提交的特性支持完成。 - InnoDB被称为事务安全型引擎。-- 事务开启 START TRANSACTION; 或者 BEGIN; 开启事务后，所有被执行的SQL语句均被认作当前事务内的SQL语句。-- 事务提交 COMMIT;-- 事务回滚 ROLLBACK; 如果部分操作发生问题，映射到事务开启前。-- 事务的特性 1. 原子性（Atomicity） 事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 2. 一致性（Consistency） 事务前后数据的完整性必须保持一致。 - 事务开始和结束时，外部数据一致 - 在整个事务过程中，操作是连续的 3. 隔离性（Isolation） 多个用户并发访问数据库时，一个用户的事务不能被其它用户的事物所干扰，多个并发事务之间的数据要相互隔离。 4. 持久性（Durability） 一个事务一旦被提交，它对数据库中的数据改变就是永久性的。-- 事务的实现 1. 要求是事务支持的表类型 2. 执行一组相关的操作前开启事务 3. 整组操作完成后，都成功，则提交；如果存在失败，选择回滚，则会回到事务开始的备份点。-- 事务的原理 利用InnoDB的自动提交(autocommit)特性完成。 普通的MySQL执行语句后，当前的数据提交操作均可被其他客户端可见。 而事务是暂时关闭“自动提交”机制，需要commit提交持久化数据操作。-- 注意 1. 数据定义语言（DDL）语句不能被回滚，比如创建或取消数据库的语句，和创建、取消或更改表或存储的子程序的语句。 2. 事务不能被嵌套-- 保存点 SAVEPOINT 保存点名称 -- 设置一个事务保存点 ROLLBACK TO SAVEPOINT 保存点名称 -- 回滚到保存点 RELEASE SAVEPOINT 保存点名称 -- 删除保存点-- InnoDB自动提交特性设置 SET autocommit = 0|1; 0表示关闭自动提交，1表示开启自动提交。 - 如果关闭了，那普通操作的结果对其他客户端也不可见，需要commit提交后才能持久化数据操作。 - 也可以关闭自动提交来开启事务。但与START TRANSACTION不同的是， SET autocommit是永久改变服务器的设置，直到下次再次修改该设置。(针对当前连接) 而START TRANSACTION记录开启前的状态，而一旦事务提交或回滚后就需要再次开启事务。(针对当前事务) 锁表1234567/* 锁表 */表锁定只用于防止其它客户端进行不正当地读取和写入MyISAM 支持表锁，InnoDB 支持行锁-- 锁定 LOCK TABLES tbl_name [AS alias]-- 解锁 UNLOCK TABLES 触发器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* 触发器 */ ------------------ 触发程序是与表有关的命名数据库对象，当该表出现特定事件时，将激活该对象 监听：记录的增加、修改、删除。-- 创建触发器CREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_stmt 参数： trigger_time是触发程序的动作时间。它可以是 before 或 after，以指明触发程序是在激活它的语句之前或之后触发。 trigger_event指明了激活触发程序的语句的类型 INSERT：将新行插入表时激活触发程序 UPDATE：更改某一行时激活触发程序 DELETE：从表中删除某一行时激活触发程序 tbl_name：监听的表，必须是永久性的表，不能将触发程序与TEMPORARY表或视图关联起来。 trigger_stmt：当触发程序激活时执行的语句。执行多个语句，可使用BEGIN...END复合语句结构-- 删除DROP TRIGGER [schema_name.]trigger_name可以使用old和new代替旧的和新的数据 更新操作，更新前是old，更新后是new. 删除操作，只有old. 增加操作，只有new.-- 注意 1. 对于具有相同触发程序动作时间和事件的给定表，不能有两个触发程序。-- 字符连接函数concat(str1,str2,...])concat_ws(separator,str1,str2,...)-- 分支语句if 条件 then 执行语句elseif 条件 then 执行语句else 执行语句end if;-- 修改最外层语句结束符delimiter 自定义结束符号 SQL语句自定义结束符号delimiter ; -- 修改回原来的分号-- 语句块包裹begin 语句块end-- 特殊的执行1. 只要添加记录，就会触发程序。2. Insert into on duplicate key update 语法会触发： 如果没有重复记录，会触发 before insert, after insert; 如果有重复记录并更新，会触发 before insert, before update, after update; 如果有重复记录但是没有发生更新，则触发 before insert, before update3. Replace 语法 如果有记录，则执行 before insert, before delete, after delete, after insert SQL编程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130/* SQL编程 */ --------------------// 局部变量 ------------ 变量声明 declare var_name[,...] type [default value] 这个语句被用来声明局部变量。要给变量提供一个默认值，请包含一个default子句。值可以被指定为一个表达式，不需要为一个常数。如果没有default子句，初始值为null。-- 赋值 使用 set 和 select into 语句为变量赋值。 - 注意：在函数内是可以使用全局变量（用户自定义的变量）--// 全局变量 ------------ 定义、赋值set 语句可以定义并为变量赋值。set @var = value;也可以使用select into语句为变量初始化并赋值。这样要求select语句只能返回一行，但是可以是多个字段，就意味着同时为多个变量进行赋值，变量的数量需要与查询的列数一致。还可以把赋值语句看作一个表达式，通过select执行完成。此时为了避免=被当作关系运算符看待，使用:=代替。（set语句可以使用= 和 :=）。select @var:=20;select @v1:=id, @v2=name from t1 limit 1;select * from tbl_name where @var:=30;select into 可以将表中查询获得的数据赋给变量。 -| select max(height) into @max_height from tb;-- 自定义变量名为了避免select语句中，用户自定义的变量与系统标识符（通常是字段名）冲突，用户自定义变量在变量名前使用@作为开始符号。@var=10; - 变量被定义后，在整个会话周期都有效（登录到退出）--// 控制结构 ------------ if语句if search_condition then statement_list [elseif search_condition then statement_list]...[else statement_list]end if;-- case语句CASE value WHEN [compare-value] THEN result[WHEN [compare-value] THEN result ...][ELSE result]END-- while循环[begin_label:] while search_condition do statement_listend while [end_label];- 如果需要在循环内提前终止 while循环，则需要使用标签；标签需要成对出现。 -- 退出循环 退出整个循环 leave 退出当前循环 iterate 通过退出的标签决定退出哪个循环--// 内置函数 ------------ 数值函数abs(x) -- 绝对值 abs(-10.9) = 10format(x, d) -- 格式化千分位数值 format(1234567.456, 2) = 1,234,567.46ceil(x) -- 向上取整 ceil(10.1) = 11floor(x) -- 向下取整 floor (10.1) = 10round(x) -- 四舍五入去整mod(m, n) -- m%n m mod n 求余 10%3=1pi() -- 获得圆周率pow(m, n) -- m^nsqrt(x) -- 算术平方根rand() -- 随机数truncate(x, d) -- 截取d位小数-- 时间日期函数now(), current_timestamp(); -- 当前日期时间current_date(); -- 当前日期current_time(); -- 当前时间date(&apos;yyyy-mm-dd hh:ii:ss&apos;); -- 获取日期部分time(&apos;yyyy-mm-dd hh:ii:ss&apos;); -- 获取时间部分date_format(&apos;yyyy-mm-dd hh:ii:ss&apos;, &apos;%d %y %a %d %m %b %j&apos;); -- 格式化时间unix_timestamp(); -- 获得unix时间戳from_unixtime(); -- 从时间戳获得时间-- 字符串函数length(string) -- string长度，字节char_length(string) -- string的字符个数substring(str, position [,length]) -- 从str的position开始,取length个字符replace(str ,search_str ,replace_str) -- 在str中用replace_str替换search_strinstr(string ,substring) -- 返回substring首次在string中出现的位置concat(string [,...]) -- 连接字串charset(str) -- 返回字串字符集lcase(string) -- 转换成小写left(string, length) -- 从string2中的左边起取length个字符load_file(file_name) -- 从文件读取内容locate(substring, string [,start_position]) -- 同instr,但可指定开始位置lpad(string, length, pad) -- 重复用pad加在string开头,直到字串长度为lengthltrim(string) -- 去除前端空格repeat(string, count) -- 重复count次rpad(string, length, pad) --在str后用pad补充,直到长度为lengthrtrim(string) -- 去除后端空格strcmp(string1 ,string2) -- 逐字符比较两字串大小-- 流程函数case when [condition] then result [when [condition] then result ...] [else result] end 多分支if(expr1,expr2,expr3) 双分支。-- 聚合函数count()sum();max();min();avg();group_concat()-- 其他常用函数md5();default();--// 存储函数，自定义函数 ------------ 新建 CREATE FUNCTION function_name (参数列表) RETURNS 返回值类型 函数体 - 函数名，应该合法的标识符，并且不应该与已有的关键字冲突。 - 一个函数应该属于某个数据库，可以使用db_name.funciton_name的形式执行当前函数所属数据库，否则为当前数据库。 - 参数部分，由&quot;参数名&quot;和&quot;参数类型&quot;组成。多个参数用逗号隔开。 - 函数体由多条可用的mysql语句，流程控制，变量声明等语句构成。 - 多条语句应该使用 begin...end 语句块包含。 - 一定要有 return 返回值语句。-- 删除 DROP FUNCTION [IF EXISTS] function_name;-- 查看 SHOW FUNCTION STATUS LIKE &apos;partten&apos; SHOW CREATE FUNCTION function_name;-- 修改 ALTER FUNCTION function_name 函数选项--// 存储过程，自定义功能 ------------ 定义存储存储过程 是一段代码（过程），存储在数据库中的sql组成。一个存储过程通常用于完成一段业务逻辑，例如报名，交班费，订单入库等。而一个函数通常专注与某个功能，视为其他程序服务的，需要在其他语句中调用函数才可以，而存储过程不能被其他调用，是自己执行 通过call执行。-- 创建CREATE PROCEDURE sp_name (参数列表) 过程体参数列表：不同于函数的参数列表，需要指明参数类型IN，表示输入型OUT，表示输出型INOUT，表示混合型注意，没有返回值。 存储过程12345678910111213141516/* 存储过程 */ ------------------存储过程是一段可执行性代码的集合。相比函数，更偏向于业务逻辑。调用：CALL 过程名-- 注意- 没有返回值。- 只能单独调用，不可夹杂在其他语句中-- 参数IN|OUT|INOUT 参数名 数据类型IN 输入：在调用过程中，将数据输入到过程体内部的参数OUT 输出：在调用过程中，将过程体处理完的结果返回到客户端INOUT 输入输出：既可输入，也可输出-- 语法CREATE PROCEDURE 过程名 (参数列表)BEGIN 过程体END 用户和权限管理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/* 用户和权限管理 */ -------------------- root密码重置1. 停止MySQL服务2. [Linux] /usr/local/mysql/bin/safe_mysqld --skip-grant-tables &amp; [Windows] mysqld --skip-grant-tables3. use mysql;4. UPDATE `user` SET PASSWORD=PASSWORD(&quot;密码&quot;) WHERE `user` = &quot;root&quot;;5. FLUSH PRIVILEGES;用户信息表：mysql.user-- 刷新权限FLUSH PRIVILEGES;-- 增加用户CREATE USER 用户名 IDENTIFIED BY [PASSWORD] 密码(字符串) - 必须拥有mysql数据库的全局CREATE USER权限，或拥有INSERT权限。 - 只能创建用户，不能赋予权限。 - 用户名，注意引号：如 &apos;user_name&apos;@&apos;192.168.1.1&apos; - 密码也需引号，纯数字密码也要加引号 - 要在纯文本中指定密码，需忽略PASSWORD关键词。要把密码指定为由PASSWORD()函数返回的混编值，需包含关键字PASSWORD-- 重命名用户RENAME USER old_user TO new_user-- 设置密码SET PASSWORD = PASSWORD(&apos;密码&apos;) -- 为当前用户设置密码SET PASSWORD FOR 用户名 = PASSWORD(&apos;密码&apos;) -- 为指定用户设置密码-- 删除用户DROP USER 用户名-- 分配权限/添加用户GRANT 权限列表 ON 表名 TO 用户名 [IDENTIFIED BY [PASSWORD] &apos;password&apos;] - all privileges 表示所有权限 - *.* 表示所有库的所有表 - 库名.表名 表示某库下面的某表 GRANT ALL PRIVILEGES ON `pms`.* TO &apos;pms&apos;@&apos;%&apos; IDENTIFIED BY &apos;pms0817&apos;;-- 查看权限SHOW GRANTS FOR 用户名 -- 查看当前用户权限 SHOW GRANTS; 或 SHOW GRANTS FOR CURRENT_USER; 或 SHOW GRANTS FOR CURRENT_USER();-- 撤消权限REVOKE 权限列表 ON 表名 FROM 用户名REVOKE ALL PRIVILEGES, GRANT OPTION FROM 用户名 -- 撤销所有权限-- 权限层级-- 要使用GRANT或REVOKE，您必须拥有GRANT OPTION权限，并且您必须用于您正在授予或撤销的权限。全局层级：全局权限适用于一个给定服务器中的所有数据库，mysql.user GRANT ALL ON *.*和 REVOKE ALL ON *.*只授予和撤销全局权限。数据库层级：数据库权限适用于一个给定数据库中的所有目标，mysql.db, mysql.host GRANT ALL ON db_name.*和REVOKE ALL ON db_name.*只授予和撤销数据库权限。表层级：表权限适用于一个给定表中的所有列，mysql.talbes_priv GRANT ALL ON db_name.tbl_name和REVOKE ALL ON db_name.tbl_name只授予和撤销表权限。列层级：列权限适用于一个给定表中的单一列，mysql.columns_priv 当使用REVOKE时，您必须指定与被授权列相同的列。-- 权限列表ALL [PRIVILEGES] -- 设置除GRANT OPTION之外的所有简单权限ALTER -- 允许使用ALTER TABLEALTER ROUTINE -- 更改或取消已存储的子程序CREATE -- 允许使用CREATE TABLECREATE ROUTINE -- 创建已存储的子程序CREATE TEMPORARY TABLES -- 允许使用CREATE TEMPORARY TABLECREATE USER -- 允许使用CREATE USER, DROP USER, RENAME USER和REVOKE ALL PRIVILEGES。CREATE VIEW -- 允许使用CREATE VIEWDELETE -- 允许使用DELETEDROP -- 允许使用DROP TABLEEXECUTE -- 允许用户运行已存储的子程序FILE -- 允许使用SELECT...INTO OUTFILE和LOAD DATA INFILEINDEX -- 允许使用CREATE INDEX和DROP INDEXINSERT -- 允许使用INSERTLOCK TABLES -- 允许对您拥有SELECT权限的表使用LOCK TABLESPROCESS -- 允许使用SHOW FULL PROCESSLISTREFERENCES -- 未被实施RELOAD -- 允许使用FLUSHREPLICATION CLIENT -- 允许用户询问从属服务器或主服务器的地址REPLICATION SLAVE -- 用于复制型从属服务器（从主服务器中读取二进制日志事件）SELECT -- 允许使用SELECTSHOW DATABASES -- 显示所有数据库SHOW VIEW -- 允许使用SHOW CREATE VIEWSHUTDOWN -- 允许使用mysqladmin shutdownSUPER -- 允许使用CHANGE MASTER, KILL, PURGE MASTER LOGS和SET GLOBAL语句，mysqladmin debug命令；允许您连接（一次），即使已达到max_connections。UPDATE -- 允许使用UPDATEUSAGE -- “无权限”的同义词GRANT OPTION -- 允许授予权限 表维护12345678/* 表维护 */-- 分析和存储表的关键字分布ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE 表名 ...-- 检查一个或多个表是否有错误CHECK TABLE tbl_name [, tbl_name] ... [option] ...option = &#123;QUICK | FAST | MEDIUM | EXTENDED | CHANGED&#125;-- 整理数据文件的碎片OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... 杂项1234567891011121314/* 杂项 */ ------------------1. 可用反引号（`）为标识符（库名、表名、字段名、索引、别名）包裹，以避免与关键字重名！中文也可以作为标识符！2. 每个库目录存在一个保存当前数据库的选项文件db.opt。3. 注释： 单行注释 # 注释内容 多行注释 /* 注释内容 */ 单行注释 -- 注释内容 (标准SQL注释风格，要求双破折号后加一空格符（空格、TAB、换行等）)4. 模式通配符： _ 任意单个字符 % 任意多个字符，甚至包括零字符 单引号需要进行转义 \\&apos;5. CMD命令行内的语句结束符可以为 &quot;;&quot;, &quot;\\G&quot;, &quot;\\g&quot;，仅影响显示结果。其他地方还是用分号结束。delimiter 可修改当前对话的语句结束符。6. SQL对大小写不敏感7. 清除已有语句：\\c","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://zhoumoon.github.io/tags/MySQL/"}]},{"title":"Mybatis-Plus 真好用","slug":"Mybatis-Plus 真好用","date":"2017-09-10T23:12:22.000Z","updated":"2021-02-08T08:14:20.150Z","comments":false,"path":"2017/09/11/Mybatis-Plus 真好用/","link":"","permalink":"http://zhoumoon.github.io/2017/09/11/Mybatis-Plus 真好用/","excerpt":"","text":"写在前面MyBatis的增强方案确实有不少，甚至有种感觉是现在如果只用 “裸MyBatis”，不来点增强插件都不好意思了。这不，在上一篇文章《Spring Boot项目利用MyBatis Generator进行数据层代码自动生成》 中尝试了一下 MyBatis Generator。这次来点更加先进的 Mybatis-Plus，SQL语句都不用写了，分页也是自动完成，嗯，真香！ 数据库准备1CREATE TABLE tbl_user( user_id BIGINT(20) NOT NULL COMMENT '主键ID', user_name VARCHAR(30) NULL DEFAULT NULL COMMENT '姓名', user_age INT(11) NULL DEFAULT NULL COMMENT '年龄', PRIMARY KEY (user_id)) charset = utf8; MyBatis-Plus加持 工程搭建 （不赘述了） 依赖引入 1234567891011121314151617181920212223&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;8.0.12&lt;/version&gt;&lt;/dependency&gt; 主要是 Mybatis Plus、Lombok（不知道Lombok干嘛的？可以看这里）、Druid连接池 等依赖。 MyBatis Plus配置 项目配置 12mybatis-plus: mapper-locations: classpath:/mapper/*Mapper.xml 新增 MyBatis Plus配置类 1234@Configuration@MapperScan(\"cn.codesheep.springbtmybatisplus.mapper\")public class MyBatisConfig &#123;&#125; 看到没，几乎零配置啊，下面就可以写业务逻辑了 业务编写 实体类 12345678@Data@TableName(\"tbl_user\")public class User &#123; @TableId(value = \"user_id\") private Long userId; private String userName; private Integer userAge;&#125; Mapper类 1public interface UserMapper extends BaseMapper&lt;User&gt; &#123;&#125; 这里啥接口方法也不用写，就可以实现增删改查了！ Service类 Service接口： 1234567public interface UserService extends IService&lt;User&gt; &#123; int insertUser( User user ); int updateUser( User user ); int deleteUser( User user ); User findUserByName( String userName ); IPage getUserPage( Page page, User user );&#125; Service实现： 12345678910111213141516171819202122232425262728@Service@AllArgsConstructorpublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService &#123; // 增 @Override public int insertUser(User user) &#123; return baseMapper.insert( user ); &#125; // 改 @Override public int updateUser(User user) &#123; return baseMapper.updateById( user ); &#125; // 删 @Override public int deleteUser(User user) &#123; return baseMapper.deleteById( user.getUserId() ); &#125; // 查 @Override public User findUserByName( String userName ) &#123; return baseMapper.getUserByName( userName ); &#125;&#125; Controller类 12345678910111213141516171819202122232425262728293031@RestController@RequestMapping(\"/user\")public class UserContorller &#123; @Autowired private UserService userService; // 增 @PostMapping( value = \"/insert\") public Object insert( @RequestBody User user ) &#123; return userService.insertUser( user ); &#125; // 改 @PostMapping( value = \"/update\") public Object update( @RequestBody User user ) &#123; return userService.updateUser( user ); &#125; // 删 @PostMapping( value = \"/delete\") public Object delete( @RequestBody User user ) &#123; return userService.deleteUser( user ); &#125; // 查 @GetMapping( value = \"/getUserByName\") public Object getUserByName( @RequestParam String userName ) &#123; return userService.findUserByName( userName ); &#125;&#125; 通过以上几个简单的步骤，我们就实现了 tbl_user表的增删改查，传统 MyBatis的 XML文件一个都不需要写！ 最关心的分页问题 首先装配分页插件 1234@Beanpublic PaginationInterceptor paginationInterceptor() &#123; return new PaginationInterceptor();&#125; Mapper类 12345678public interface UserMapper extends BaseMapper&lt;User&gt; &#123; // 普通查询 User getUserByName( String userName ); // 分页查询 IPage&lt;List&lt;User&gt;&gt; getUsersPage( Page page, @Param(\"query\") User user );&#125; Service类 12345678910111213141516@Service@AllArgsConstructorpublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService &#123; // 查：普通查 @Override public User findUserByName( String userName ) &#123; return baseMapper.getUserByName( userName ); &#125; // 分页查 @Override public IPage getUserPage(Page page, User user) &#123; return baseMapper.getUsersPage( page, user ); &#125;&#125; Controller类 1234@GetMapping( value = \"/page\")public Object getUserPage( Page page, User user ) &#123; return userService.getUserPage( page, user );&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://zhoumoon.github.io/tags/Java/"}]},{"title":"MySQL高性能优化规范建议","slug":"MySQL高性能优化规范建议","date":"2017-07-12T07:12:00.000Z","updated":"2021-02-08T08:14:20.138Z","comments":false,"path":"2017/07/12/MySQL高性能优化规范建议/","link":"","permalink":"http://zhoumoon.github.io/2017/07/12/MySQL高性能优化规范建议/","excerpt":"","text":"数据库命令规范 数据库基本设计规范 1. 所有表必须使用 Innodb 存储引擎 2. 数据库和表的字符集统一使用 UTF8 3. 所有表和字段都需要添加注释 4. 尽量控制单表数据量的大小,建议控制在 500 万以内。 5. 谨慎使用 MySQL 分区表 6.尽量做到冷热数据分离,减小表的宽度 7. 禁止在表中建立预留字段 8. 禁止在数据库中存储图片,文件等大的二进制数据 9. 禁止在线上做数据库压力测试 10. 禁止从开发环境,测试环境直接连接生成环境数据库 数据库字段设计规范 1. 优先选择符合存储需要的最小的数据类型 2. 避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据 3. 避免使用 ENUM 类型 4. 尽可能把所有列定义为 NOT NULL 5. 使用 TIMESTAMP(4 个字节) 或 DATETIME 类型 (8 个字节) 存储时间 6. 同财务相关的金额类数据必须使用 decimal 类型 索引设计规范 1. 限制每张表上的索引数量,建议单张表索引不超过 5 个 2. 禁止给表中的每一列都建立单独的索引 3. 每个 Innodb 表必须有个主键 4. 常见索引列建议 5.如何选择索引列的顺序 6. 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间） 7. 对于频繁的查询优先考虑使用覆盖索引 8.索引 SET 规范 数据库 SQL 开发规范 1. 建议使用预编译语句进行数据库操作 2. 避免数据类型的隐式转换 3. 充分利用表上已经存在的索引 4. 数据库设计时，应该要对以后扩展进行考虑 5. 程序连接不同的数据库使用不同的账号，进制跨库查询 6. 禁止使用 SELECT * 必须使用 SELECT &lt;字段列表&gt; 查询 7. 禁止使用不含字段列表的 INSERT 语句 8. 避免使用子查询，可以把子查询优化为 join 操作 9. 避免使用 JOIN 关联太多的表 10. 减少同数据库的交互次数 11. 对应同一列进行 or 判断时，使用 in 代替 or 12. 禁止使用 order by rand() 进行随机排序 13. WHERE 从句中禁止对列进行函数转换和计算 14. 在明显不会有重复值时使用 UNION ALL 而不是 UNION 15. 拆分复杂的大 SQL 为多个小 SQL 数据库操作行为规范 1. 超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作 2. 对于大表使用 pt-online-schema-change 修改表结构 3. 禁止为程序使用的账号赋予 super 权限 4. 对于程序连接数据库账号,遵循权限最小原则 数据库命令规范 所有数据库对象名称必须使用小写字母并用下划线分割 所有数据库对象名称禁止使用 MySQL 保留关键字（如果表名中包含关键字查询时，需要将其用单引号括起来） 数据库对象的命名要能做到见名识意，并且最后不要超过 32 个字符 临时库表必须以 tmp_为前缀并以日期为后缀，备份表必须以 bak_为前缀并以日期 (时间戳) 为后缀 所有存储相同数据的列名和列类型必须一致（一般作为关联列，如果查询时关联列类型不一致会自动进行数据类型隐式转换，会造成列上的索引失效，导致查询效率降低） 数据库基本设计规范1. 所有表必须使用 Innodb 存储引擎没有特殊要求（即 Innodb 无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用 Innodb 存储引擎（MySQL5.5 之前默认使用 Myisam，5.6 以后默认的为 Innodb）。 Innodb 支持事务，支持行级锁，更好的恢复性，高并发下性能更好。 2. 数据库和表的字符集统一使用 UTF8兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效，如果数据库中有存储 emoji 表情的需要，字符集需要采用 utf8mb4 字符集。 3. 所有表和字段都需要添加注释使用 comment 从句添加表和列的备注，从一开始就进行数据字典的维护 4. 尽量控制单表数据量的大小,建议控制在 500 万以内。500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。 可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小 5. 谨慎使用 MySQL 分区表分区表在物理上表现为多个文件，在逻辑上表现为一个表； 谨慎选择分区键，跨分区查询效率可能更低； 建议采用物理分表的方式管理大数据。 6.尽量做到冷热数据分离,减小表的宽度 MySQL 限制每个表最多存储 4096 列，并且每一行数据的大小不能超过 65535 字节。 减少磁盘 IO,保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的 IO）； 更有效的利用缓存，避免读入无用的冷数据； 经常一起使用的列放到一个表中（避免更多的关联操作）。 7. 禁止在表中建立预留字段预留字段的命名很难做到见名识义。 预留字段无法确认存储的数据类型，所以无法选择合适的类型。 对预留字段类型的修改，会对表进行锁定。 8. 禁止在数据库中存储图片,文件等大的二进制数据通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机 IO 操作，文件很大时，IO 操作很耗时。 通常存储于文件服务器，数据库只存储文件地址信息 9. 禁止在线上做数据库压力测试10. 禁止从开发环境,测试环境直接连接生产环境数据库 数据库字段设计规范1. 优先选择符合存储需要的最小的数据类型原因： 列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少也越少，在遍历时所需要的 IO 次数也就越多，索引的性能也就越差。 方法： a.将字符串转换成数字类型存储,如:将 IP 地址转换成整形数据 MySQL 提供了两个方法来处理 ip 地址 inet_aton 把 ip 转为无符号整型 (4-8 位) inet_ntoa 把整型的 ip 转为地址 插入数据前，先用 inet_aton 把 ip 地址转为整型，可以节省空间，显示数据时，使用 inet_ntoa 把整型的 ip 地址转为地址显示即可。 b.对于非负型的数据 (如自增 ID,整型 IP) 来说,要优先使用无符号整型来存储 原因： 无符号相对于有符号可以多出一倍的存储空间 12SIGNED INT -2147483648~2147483647UNSIGNED INT 0~4294967295 VARCHAR(N) 中的 N 代表的是字符数，而不是字节数，使用 UTF8 存储 255 个汉字 Varchar(255)=765 个字节。过大的长度会消耗更多的内存。 2. 避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据a. 建议把 BLOB 或是 TEXT 列分离到单独的扩展表中 MySQL 内存临时表不支持 TEXT、BLOB 这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，MySQL 还是要进行二次查询，会使 sql 性能变得很差，但是不是说一定不能使用这样的数据类型。 如果一定要使用，建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，查询时一定不要使用 select * 而只需要取出必要的列，不需要 TEXT 列的数据时不要对该列进行查询。 2、TEXT 或 BLOB 类型只能使用前缀索引 因为MySQL 对索引字段长度是有限制的，所以 TEXT 类型只能使用前缀索引，并且 TEXT 列上是不能有默认值的 3. 避免使用 ENUM 类型修改 ENUM 值需要使用 ALTER 语句 ENUM 类型的 ORDER BY 操作效率低，需要额外操作 禁止使用数值作为 ENUM 的枚举值 4. 尽可能把所有列定义为 NOT NULL原因： 索引 NULL 列需要额外的空间来保存，所以要占用更多的空间 进行比较和计算时要对 NULL 值做特别的处理 5. 使用 TIMESTAMP(4 个字节) 或 DATETIME 类型 (8 个字节) 存储时间TIMESTAMP 存储的时间范围 1970-01-01 00:00:01 ~ 2038-01-19-03:14:07 TIMESTAMP 占用 4 字节和 INT 相同，但比 INT 可读性高 超出 TIMESTAMP 取值范围的使用 DATETIME 类型存储 经常会有人用字符串存储日期型的数据（不正确的做法） 缺点 1：无法用日期函数进行计算和比较 缺点 2：用字符串存储日期要占用更多的空间 6. 同财务相关的金额类数据必须使用 decimal 类型 非精准浮点：float,double 精准浮点：decimal Decimal 类型为精准浮点数，在计算时不会丢失精度 占用空间由定义的宽度决定，每 4 个字节可以存储 9 位数字，并且小数点要占用一个字节 可用于存储比 bigint 更大的整型数据 索引设计规范1. 限制每张表上的索引数量,建议单张表索引不超过 5 个索引并不是越多越好！索引可以提高效率同样可以降低效率。 索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。 因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能。 2. 禁止给表中的每一列都建立单独的索引5.6 版本之前，一个 sql 只能使用到一个表中的一个索引，5.6 以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好。 3. 每个 Innodb 表必须有个主键Innodb 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。 Innodb 是按照主键索引的顺序来组织表的 不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引） 不要使用 UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长） 主键建议使用自增 ID 值 4. 常见索引列建议 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列 包含在 ORDER BY、GROUP BY、DISTINCT 中的字段 并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好 多表 join 的关联列 5.如何选择索引列的顺序建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。 区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数） 尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好） 使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引） 6. 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间） 重复索引示例：primary key(id)、index(id)、unique index(id) 冗余索引示例：index(a,b,c)、index(a,b)、index(a) 7. 对于频繁的查询优先考虑使用覆盖索引 覆盖索引：就是包含了所有查询字段 (where,select,ordery by,group by 包含的字段) 的索引 覆盖索引的好处： 避免 Innodb 表进行索引的二次查询: Innodb 是以聚集索引的顺序来存储的，对于 Innodb 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了 IO 操作，提升了查询效率。 可以把随机 IO 变成顺序 IO 加快查询效率: 由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。 8.索引 SET 规范尽量避免使用外键约束 不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引 外键可用于保证数据的参照完整性，但建议在业务端实现 外键会影响父表和子表的写操作从而降低性能 数据库 SQL 开发规范1. 建议使用预编译语句进行数据库操作预编译语句可以重复使用这些计划，减少 SQL 编译所需要的时间，还可以解决动态 SQL 所带来的 SQL 注入的问题。 只传参数，比传递 SQL 语句更高效。 相同语句可以一次解析，多次使用，提高处理效率。 2. 避免数据类型的隐式转换隐式转换会导致索引失效如: 1select name,phone from customer where id = &apos;111&apos;; 3. 充分利用表上已经存在的索引避免使用双%号的查询条件。如：a like &#39;%123%&#39;，（如果无前置%,只有后置%，是可以用到列上的索引的） 一个 SQL 只能利用到复合索引中的一列进行范围查询。如：有 a,b,c 列的联合索引，在查询条件中有 a 列的范围查询，则在 b,c 列上的索引将不会被用到。 在定义联合索引时，如果 a 列要用到范围查找的话，就要把 a 列放到联合索引的右侧，使用 left join 或 not exists 来优化 not in 操作，因为 not in 也通常会使用索引失效。 4. 数据库设计时，应该要对以后扩展进行考虑5. 程序连接不同的数据库使用不同的账号，禁止跨库查询 为数据库迁移和分库分表留出余地 降低业务耦合度 避免权限过大而产生的安全风险 6. 禁止使用 SELECT * 必须使用 SELECT &lt;字段列表&gt; 查询原因： 消耗更多的 CPU 和 IO 以网络带宽资源 无法使用覆盖索引 可减少表结构变更带来的影响 7. 禁止使用不含字段列表的 INSERT 语句如： 1insert into values (&apos;a&apos;,&apos;b&apos;,&apos;c&apos;); 应使用： 1insert into t(c1,c2,c3) values (&apos;a&apos;,&apos;b&apos;,&apos;c&apos;); 8. 避免使用子查询，可以把子查询优化为 join 操作通常子查询在 in 子句中，且子查询中为简单 SQL(不包含 union、group by、order by、limit 从句) 时,才可以把子查询转化为关联查询进行优化。 子查询性能差的原因： 子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大。 由于子查询会产生大量的临时表也没有索引，所以会消耗过多的 CPU 和 IO 资源，产生大量的慢查询。 9. 避免使用 JOIN 关联太多的表对于 MySQL 来说，是存在关联缓存的，缓存的大小可以由 join_buffer_size 参数进行设置。 在 MySQL 中，对于同一个 SQL 多关联（join）一个表，就会多分配一个关联缓存，如果在一个 SQL 中关联的表越多，所占用的内存也就越大。 如果程序中大量的使用了多表关联的操作，同时 join_buffer_size 设置的也不合理的情况下，就容易造成服务器内存溢出的情况，就会影响到服务器数据库性能的稳定性。 同时对于关联操作来说，会产生临时表操作，影响查询效率，MySQL 最多允许关联 61 个表，建议不超过 5 个。 10. 减少同数据库的交互次数数据库更适合处理批量操作，合并多个相同的操作到一起，可以提高处理效率。 11. 对应同一列进行 or 判断时，使用 in 代替 orin 的值不要超过 500 个，in 操作可以更有效的利用索引，or 大多数情况下很少能利用到索引。 12. 禁止使用 order by rand() 进行随机排序order by rand() 会把表中所有符合条件的数据装载到内存中，然后在内存中对所有数据根据随机生成的值进行排序，并且可能会对每一行都生成一个随机值，如果满足条件的数据集非常大，就会消耗大量的 CPU 和 IO 及内存资源。 推荐在程序中获取一个随机值，然后从数据库中获取数据的方式。 13. WHERE 从句中禁止对列进行函数转换和计算对列进行函数转换或计算时会导致无法使用索引 不推荐： 1where date(create_time)=&apos;20190101&apos; 推荐： 1where create_time &gt;= &apos;20190101&apos; and create_time &lt; &apos;20190102&apos; 14. 在明显不会有重复值时使用 UNION ALL 而不是 UNION UNION 会把两个结果集的所有数据放到临时表中后再进行去重操作 UNION ALL 不会再对结果集进行去重操作 15. 拆分复杂的大 SQL 为多个小 SQL 大 SQL 逻辑上比较复杂，需要占用大量 CPU 进行计算的 SQL MySQL 中，一个 SQL 只能使用一个 CPU 进行计算 SQL 拆分后可以通过并行执行来提高处理效率 数据库操作行为规范1. 超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作大批量操作可能会造成严重的主从延迟 主从环境中,大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间，而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况 binlog 日志为 row 格式时会产生大量的日志 大批量写操作会产生大量日志，特别是对于 row 格式二进制数据而言，由于在 row 格式中会记录每一行数据的修改，我们一次修改的数据越多，产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因 避免产生大事务操作 大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对 MySQL 的性能产生非常大的影响。 特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批 2. 对于大表使用 pt-online-schema-change 修改表结构 避免大表修改产生的主从延迟 避免在对表字段进行修改时进行锁表 对大表数据结构的修改一定要谨慎，会造成严重的锁表操作，尤其是生产环境，是不能容忍的。 pt-online-schema-change 它会首先建立一个与原表结构相同的新表，并且在新表上进行表结构的修改，然后再把原表中的数据复制到新表中，并在原表中增加一些触发器。把原表中新增的数据也复制到新表中，在行所有数据复制完成之后，把新表命名成原表，并把原来的表删除掉。把原来一个 DDL 操作，分解成多个小的批次进行。 3. 禁止为程序使用的账号赋予 super 权限 当达到最大连接数限制时，还运行 1 个有 super 权限的用户连接 super 权限只能留给 DBA 处理问题的账号使用 4. 对于程序连接数据库账号,遵循权限最小原则 程序使用数据库账号只能在一个 DB 下使用，不准跨库 程序使用的账号原则上不准有 drop 权限","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://zhoumoon.github.io/tags/MySQL/"}]}],"categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://zhoumoon.github.io/tags/Java/"},{"name":"Http","slug":"Http","permalink":"http://zhoumoon.github.io/tags/Http/"},{"name":"MySQL","slug":"MySQL","permalink":"http://zhoumoon.github.io/tags/MySQL/"}]}